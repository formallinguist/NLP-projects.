{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdE6Z7BICzhk"
      },
      "source": [
        "# TRAINING TEXT CLASSIFIERS WITH SPACY\n",
        "\n",
        "In this lab we will train different text classifiers with spacy.\n",
        "\n",
        "1. Read through the code and train to add more inline documentation as you try to understand the functionality.\n",
        "\n",
        "2. We will adapt the code to train two different fake news classifiers: one on general fake news from 6 different domains and another one on celebrities, were there are legitimate news but also news which are false gossip.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbtb9NusdN1d",
        "outputId": "232c796c-4933-468d-a9cc-743e047c454c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQCUHxFt3GYh",
        "outputId": "1308f0b2-5d3c-412b-cc0d-12b9fb1f834c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy==2.3.7\n",
            "  Downloading spacy-2.3.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (3.0.8)\n",
            "Collecting srsly<1.1.0,>=1.0.2\n",
            "  Downloading srsly-1.0.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (2.0.7)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (4.64.1)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (2.25.1)\n",
            "Collecting plac<1.2.0,>=0.9.6\n",
            "  Downloading plac-1.1.3-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (0.7.9)\n",
            "Collecting catalogue<1.1.0,>=0.0.7\n",
            "  Downloading catalogue-1.0.2-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy==2.3.7) (1.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (2.10)\n",
            "Installing collected packages: plac, srsly, catalogue, thinc, spacy\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 2.4.5\n",
            "    Uninstalling srsly-2.4.5:\n",
            "      Successfully uninstalled srsly-2.4.5\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 2.0.8\n",
            "    Uninstalling catalogue-2.0.8:\n",
            "      Successfully uninstalled catalogue-2.0.8\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.7\n",
            "    Uninstalling thinc-8.1.7:\n",
            "      Successfully uninstalled thinc-8.1.7\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.4\n",
            "    Uninstalling spacy-3.4.4:\n",
            "      Successfully uninstalled spacy-3.4.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 2.3.7 which is incompatible.\n",
            "confection 0.0.4 requires srsly<3.0.0,>=2.4.0, but you have srsly 1.0.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed catalogue-1.0.2 plac-1.1.3 spacy-2.3.7 srsly-1.0.6 thinc-7.4.6\n"
          ]
        }
      ],
      "source": [
        "# We will be using spacy v2\n",
        "!pip install -U spacy==2.3.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIZTbJw_7RNE",
        "outputId": "90009455-e5f3-43eb-aad5-d4dd638e1f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.8/dist-packages (2.3.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (4.64.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy) (7.4.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (2.25.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (0.7.9)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.25.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.9)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.6)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.8)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.0.0)\n",
            "Building wheels for collected packages: en_core_web_sm\n",
            "  Building wheel for en_core_web_sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en_core_web_sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047104 sha256=2b54f28d87e2b9fa36f6b8db074148ff0a342a68d5087b9b4b0c5f53c452e771\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/4d/f7/563214122be1540b5f9197b52cb3ddb9c4a8070808b22d5a84\n",
            "Successfully built en_core_web_sm\n",
            "Installing collected packages: en_core_web_sm\n",
            "  Attempting uninstall: en_core_web_sm\n",
            "    Found existing installation: en-core-web-sm 3.4.1\n",
            "    Uninstalling en-core-web-sm-3.4.1:\n",
            "      Successfully uninstalled en-core-web-sm-3.4.1\n",
            "Successfully installed en_core_web_sm-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "python3: can't open file 'https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.0/en_core_web_lg-2.2.0.tar.gz': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# TODO install and test the language modules of your choice following the https://spacy.io/usage\n",
        "\n",
        "!pip install spacy\n",
        "\n",
        "!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy download en_core_web_md\n",
        "!python https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.0/en_core_web_lg-2.2.0.tar.gz\n",
        "#nlp = spacy.load(\"en_core_web_sm\")\n",
        "#nlp = spacy.load(\"en_core_web_md\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9S-N6UPAsyyE"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import csv\n",
        "import random\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "\n",
        "from spacy.util import minibatch, compounding\n",
        "import sys\n",
        "from spacy import displacy\n",
        "from itertools import chain\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# TODO add inline documentation describing the functionality of each function\n",
        "\n",
        "''' The \"load_data\" function loads data from multiple files specified in the input list \"fnames\".\n",
        "Each file is loaded into a Pandas DataFrame using the \"pd.read_csv\" function, separated by tab characters and encoded in 'utf-8'.\n",
        "The loaded data from each file is concatenated into a single DataFrame using \"pd.concat\".\n",
        "The unique values of the 'Target' column are extracted and stored in a list \"targets\",\n",
        " and the combined DataFrame and the list of targets are returned by the function.'''\n",
        "\n",
        "# load data\n",
        "def load_data(fnames):\n",
        "    data = []\n",
        "    for fname in fnames:\n",
        "        data.append(pd.read_csv(fname, sep='\\t', encoding='utf-8'))\n",
        "    data = pd.concat(data)\n",
        "    targets = set(data['Target'])\n",
        "    return data, list(targets)\n",
        "\n",
        "# pre-process tweets\n",
        "def cleanup(tweet):\n",
        "    \"\"\"we remove urls, hashtags and user symbols\"\"\"\n",
        "    tweet = re.sub(r\"http\\S+\", \"\", tweet.replace(\"#\", \"\").replace(\"@\", \"\").replace('\\n', ' ').replace('\\t', ' '))\n",
        "    return tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "It1ah6R0wXWZ",
        "outputId": "8834bafb-6326-4420-e76a-ffeaf8b87726"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        ID                    Target  \\\n",
              "0        1           Hillary Clinton   \n",
              "1        2           Hillary Clinton   \n",
              "2        3           Hillary Clinton   \n",
              "3        4           Hillary Clinton   \n",
              "4        5           Hillary Clinton   \n",
              "...    ...                       ...   \n",
              "2809  2910  Legalization of Abortion   \n",
              "2810  2911  Legalization of Abortion   \n",
              "2811  2912  Legalization of Abortion   \n",
              "2812  2913  Legalization of Abortion   \n",
              "2813  2914  Legalization of Abortion   \n",
              "\n",
              "                                                  Tweet   Stance  \\\n",
              "0     @tedcruz And, #HandOverTheServer she wiped cle...  AGAINST   \n",
              "1     Hillary is our best choice if we truly want to...    FAVOR   \n",
              "2     @TheView I think our country is ready for a fe...  AGAINST   \n",
              "3     I just gave an unhealthy amount of my hard-ear...  AGAINST   \n",
              "4     @PortiaABoulger Thank you for adding me to you...     NONE   \n",
              "...                                                 ...      ...   \n",
              "2809  There's a law protecting unborn eagles, but no...  AGAINST   \n",
              "2810  I am 1 in 3... I have had an abortion #Abortio...  AGAINST   \n",
              "2811  How dare you say my sexual preference is a cho...  AGAINST   \n",
              "2812  Equal rights for those 'born that way', no rig...  AGAINST   \n",
              "2813  #POTUS seals his legacy w/ 1/2 doz wins. The #...  AGAINST   \n",
              "\n",
              "                                            Clean_tweet  \n",
              "0     tedcruz And, HandOverTheServer she wiped clean...  \n",
              "1     Hillary is our best choice if we truly want to...  \n",
              "2     TheView I think our country is ready for a fem...  \n",
              "3     I just gave an unhealthy amount of my hard-ear...  \n",
              "4     PortiaABoulger Thank you for adding me to your...  \n",
              "...                                                 ...  \n",
              "2809  There's a law protecting unborn eagles, but no...  \n",
              "2810  I am 1 in 3... I have had an abortion Abortion...  \n",
              "2811  How dare you say my sexual preference is a cho...  \n",
              "2812  Equal rights for those 'born that way', no rig...  \n",
              "2813  POTUS seals his legacy w/ 1/2 doz wins. The GO...  \n",
              "\n",
              "[2914 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-616789b0-cbec-4219-bb9e-d350cbee0341\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>tedcruz And, HandOverTheServer she wiped clean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>TheView I think our country is ready for a fem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>PortiaABoulger Thank you for adding me to your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>2910</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>There's a law protecting unborn eagles, but no...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>There's a law protecting unborn eagles, but no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2810</th>\n",
              "      <td>2911</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>I am 1 in 3... I have had an abortion #Abortio...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>I am 1 in 3... I have had an abortion Abortion...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811</th>\n",
              "      <td>2912</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>How dare you say my sexual preference is a cho...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>How dare you say my sexual preference is a cho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2812</th>\n",
              "      <td>2913</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>Equal rights for those 'born that way', no rig...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Equal rights for those 'born that way', no rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>2914</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>#POTUS seals his legacy w/ 1/2 doz wins. The #...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>POTUS seals his legacy w/ 1/2 doz wins. The GO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2914 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616789b0-cbec-4219-bb9e-d350cbee0341')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-616789b0-cbec-4219-bb9e-d350cbee0341 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-616789b0-cbec-4219-bb9e-d350cbee0341');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# data path. trial data used as training too.\n",
        "trial_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-trialdata.utf-8.txt\"\n",
        "train_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-trainingdata.utf-8.txt\"\n",
        "test_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-testdata-gold.txt\"\n",
        "\n",
        "training_data, targets = load_data([trial_file, train_file])\n",
        "training_data['Clean_tweet'] = training_data['Tweet'].apply(cleanup)\n",
        "\n",
        "test_data, _ = load_data([test_file])\n",
        "test_data['Clean_tweet'] = test_data['Tweet'].apply(cleanup)\n",
        "display(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "pc-5nX2DESYy"
      },
      "outputs": [],
      "source": [
        "for target in targets:\n",
        "  training_data[training_data['Target'] == target][['Stance', 'Clean_tweet']].to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.{target}.tsv\",\n",
        "          sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")\n",
        "  test_data[test_data['Target'] == target][['Stance', 'Clean_tweet']].to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.{target}.tsv\",\n",
        "          sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUcJndNsCt4u"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TvjWbWcwZf1W"
      },
      "outputs": [],
      "source": [
        "'''The function loads a CSV file into a pandas dataframe \"training_data\".\n",
        "It then outputs the count of each unique value in the \"Stance\" column.\n",
        "The \"Clean_tweet\" and \"Stance\" columns are extracted into lists \"train_texts\" and \"train_cats\".\n",
        "A list of dictionaries \"final_train_cats\" with binary values is created to represent the stance categories.\n",
        "The function returns the list of tuples \"train_data\", the \"train_texts\" and \"train_cats\"\n",
        "'''\n",
        "\n",
        "def load_data_spacy(fname):\n",
        "  training_data = pd.read_csv(fname, sep='\\t', encoding='utf-8')\n",
        "  #train_data.dropna(axis = 0, how ='any',inplace=True)\n",
        "  #train_data['Num_words_text'] = train_data['text'].apply(lambda x:len(str(x).split())) \n",
        "  #mask = train_data['Num_words_text'] >2\n",
        "  #train_data = train_data[mask]\n",
        "  print(training_data['Stance'].value_counts())\n",
        "   \n",
        "  train_texts = training_data['Clean_tweet'].tolist()\n",
        "  train_cats = training_data['Stance'].tolist()\n",
        "  final_train_cats=[]\n",
        "  for cat in train_cats:\n",
        "    cat_list = {}\n",
        "    if cat == 'AGAINST':\n",
        "      cat_list['AGAINST'] =  1\n",
        "      cat_list['FAVOR'] =  0\n",
        "      cat_list['NONE'] =  0\n",
        "    elif cat == 'FAVOR':\n",
        "      cat_list['AGAINST'] =  0\n",
        "      cat_list['FAVOR'] =  1\n",
        "      cat_list['NONE'] =  0\n",
        "    else:\n",
        "      cat_list['AGAINST'] =  0\n",
        "      cat_list['FAVOR'] =  0\n",
        "      cat_list['NONE'] =  1\n",
        "    final_train_cats.append(cat_list)\n",
        "    \n",
        "  train_data = list(zip(train_texts, [{\"cats\": cats} for cats in final_train_cats]))\n",
        "  return train_data, train_texts, train_cats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqxmbgRXzPxC",
        "outputId": "9696d041-5d82-4927-b436-3e55378eb687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGAINST    328\n",
            "FAVOR      210\n",
            "NONE       126\n",
            "Name: Stance, dtype: int64\n",
            "[('Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. manly SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Sometimes I overheat and want to take off my shirt but can't because of social expectations of people with breasts. ;n; SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('If feminists spent 1/2 as much time reading papers as they do tumblr they would be real people, not ignorant sexist bigots. SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Stupid Feminists, the civilization you take for granted was built with the labour, blood sweat and tears of men. SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"YOU'RE A GIRL AND HAVE A SEX DRIVE!? YOU MUST BE A SLUT! feminist SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Suns out....  Dresses out...  StreetHarassment out...  This shouldn't be daily life  YesAllWomen EverydaySexism SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Women's rights are humanrights! Join the CPDvoices twitter rally at 3pm ET if you agree! CPD48 SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"So you support unequal pricing based on gender CamilleBogrand?  Don't you normally call that sexism?  EqualPayDay SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('These pics of pornstars with/without makeup? Just perpetuating the myth that women need makeup to be considered pretty. SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('YesAllWomen should know how to protect herself. Which is why I carry a gun. republicanvalues SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}})]\n",
            "664\n",
            "AGAINST    183\n",
            "FAVOR       58\n",
            "NONE        44\n",
            "Name: Stance, dtype: int64\n",
            "285\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Feminist Movement.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Feminist Movement.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fVVY29A557be"
      },
      "outputs": [],
      "source": [
        "'''This function sorts a list of sublists in descending order based on the second element of each sublist.\n",
        " The \"key\" parameter of the \"sorted\" function is set to a lambda function that returns the second element of each sublist, and the\n",
        "  \"reverse\" parameter is set to \"True\", \n",
        "so the resulting list will be sorted in descending order. '''\n",
        "\n",
        "def Sort(sub_li):\n",
        "  # reverse = True (Soresulting_list = list(first_list)rts in Descending  order) \n",
        "  # key is set to sort using second element of  \n",
        "  # sublist lambda has been used \n",
        "  return(sorted(sub_li, key = lambda x: x[1],reverse=True))  \n",
        "\n",
        "# run the predictions on each sentence in the evaluation  dataset, and return the metrics\n",
        "'''The \"evaluate\" function evaluates the performance of a tokenizer and a text categorization model on a set of test text data.\n",
        " It tokenizes the test texts, processes them through the text categorization model to get prediction scores for each text, extracts the top-rated category for each text,\n",
        "  and compares the predicted categories with the true categories. The function then prints a performance evaluation report in terms of precision, recall, and F1-score for each class. '''\n",
        "def evaluate(tokenizer, textcat, test_texts, test_cats ):\n",
        "  docs = (tokenizer(text) for text in test_texts)\n",
        "  preds = []\n",
        "  for i, doc in enumerate(textcat.pipe(docs)):\n",
        "    #print(doc.cats.items())\n",
        "    scores = Sort(doc.cats.items())\n",
        "    #print(scores)\n",
        "    catList=[]\n",
        "    for score in scores:\n",
        "      catList.append(score[0])\n",
        "    preds.append(catList[0])\n",
        "        \n",
        "  labels = ['AGAINST', 'FAVOR']\n",
        " \n",
        "  print(classification_report(test_cats, preds,labels=labels))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UoYAGQHvILqV"
      },
      "outputs": [],
      "source": [
        "def train_spacy(  train_data, iterations,test_texts,test_cats, model_arch, dropout = 0.3, model=None, init_tok2vec=None):\n",
        "    ''' Train a spacy model, which can be queried against with test data\n",
        "   \n",
        "    train_data : training data in the format of (sentence, {cats: ['AGAINST'|'FAVOR'|'NONE']})\n",
        "    labels : a list of unique annotations\n",
        "    iterations : number of training iterations\n",
        "    dropout : dropout proportion for training\n",
        "    display_freq : number of epochs between logging losses to console\n",
        "    '''\n",
        "    \n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    \n",
        "\n",
        "    # add the text classifier to the pipeline if it doesn't exist\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"textcat\" not in nlp.pipe_names:\n",
        "        textcat = nlp.create_pipe(\n",
        "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": model_arch}\n",
        "        )\n",
        "        nlp.add_pipe(textcat, last=True)\n",
        "        \n",
        "    # otherwise, get it, so we can add labels to it\n",
        "    else:\n",
        "        textcat = nlp.get_pipe(\"textcat\")\n",
        "\n",
        "    # add label to text classifier\n",
        "    textcat.add_label(\"AGAINST\")\n",
        "    textcat.add_label(\"FAVOR\")\n",
        "    textcat.add_label(\"NONE\")\n",
        "   \n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
        "        optimizer = nlp.begin_training()\n",
        "        if init_tok2vec is not None:\n",
        "            with init_tok2vec.open(\"rb\") as file_:\n",
        "                textcat.model.tok2vec.from_bytes(file_.read())\n",
        "        print(\"Training the model...\")\n",
        "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "        batch_sizes = compounding(16.0, 64.0, 1.5)\n",
        "        for i in range(iterations):\n",
        "            print('Iteration: '+str(i))\n",
        "            #start_time = time.process_time()\n",
        "            losses = {}\n",
        "            # batch up the examples using spaCy's minibatch\n",
        "            random.shuffle(train_data)\n",
        "            batches = minibatch(train_data, size=batch_sizes)\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
        "            with textcat.model.use_params(optimizer.averages):\n",
        "                # evaluate on the test data \n",
        "                evaluate(nlp.tokenizer, textcat, test_texts,test_cats)\n",
        "            #print ('Elapsed time'+str(time.process_time() - start_time)+  \"seconds\")\n",
        "        with nlp.use_params(optimizer.averages):\n",
        "            model_name = model_arch + \"_hiliary_clinton\"\n",
        "            #model_name = model_arch + \"_legalization_of_abortion\"\n",
        "            #model_name = model_arch + \"_Atheism\"\n",
        "            #model_name = model_arch + \"_climate_change\"\n",
        "            #model_name = model_arch + \"_feminism\"\n",
        "            filepath = \"/content/drive/MyDrive/NLP_Applications_1/DATA\" + model_name \n",
        "            nlp.to_disk(filepath)\n",
        "    return nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OorDhD-vMSfN",
        "outputId": "3d7ed8be-59f9-4e40-deea-04b39da3b77c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      1.00      0.78       183\n",
            "       FAVOR       0.00      0.00      0.00        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.32      0.50      0.39       241\n",
            "weighted avg       0.49      0.76      0.59       241\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      1.00      0.78       183\n",
            "       FAVOR       0.00      0.00      0.00        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.32      0.50      0.39       241\n",
            "weighted avg       0.49      0.76      0.59       241\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      1.00      0.78       183\n",
            "       FAVOR       0.00      0.00      0.00        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.32      0.50      0.39       241\n",
            "weighted avg       0.49      0.76      0.59       241\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.65      0.99      0.78       183\n",
            "       FAVOR       0.33      0.03      0.06        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.49      0.51      0.42       241\n",
            "weighted avg       0.57      0.76      0.61       241\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.65      0.98      0.78       183\n",
            "       FAVOR       0.30      0.05      0.09        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.69       241\n",
            "   macro avg       0.48      0.51      0.43       241\n",
            "weighted avg       0.57      0.76      0.61       241\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.65      0.94      0.77       183\n",
            "       FAVOR       0.25      0.09      0.13        58\n",
            "\n",
            "   micro avg       0.62      0.73      0.67       241\n",
            "   macro avg       0.45      0.51      0.45       241\n",
            "weighted avg       0.55      0.73      0.61       241\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.91      0.77       183\n",
            "       FAVOR       0.34      0.19      0.24        58\n",
            "\n",
            "   micro avg       0.62      0.74      0.68       241\n",
            "   macro avg       0.50      0.55      0.51       241\n",
            "weighted avg       0.58      0.74      0.64       241\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.67      0.89      0.76       183\n",
            "       FAVOR       0.32      0.22      0.26        58\n",
            "\n",
            "   micro avg       0.62      0.73      0.67       241\n",
            "   macro avg       0.49      0.56      0.51       241\n",
            "weighted avg       0.58      0.73      0.64       241\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.88      0.76       183\n",
            "       FAVOR       0.36      0.29      0.32        58\n",
            "\n",
            "   micro avg       0.62      0.74      0.68       241\n",
            "   macro avg       0.52      0.59      0.54       241\n",
            "weighted avg       0.60      0.74      0.66       241\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.87      0.77       183\n",
            "       FAVOR       0.40      0.38      0.39        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.69       241\n",
            "   macro avg       0.55      0.63      0.58       241\n",
            "weighted avg       0.62      0.76      0.68       241\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 10, test_texts, test_cats, \"bow\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noB8ldyTPJ8m",
        "outputId": "5ec42156-de41-4e51-bcce-922e5205201f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      1.00      0.78       183\n",
            "       FAVOR       0.00      0.00      0.00        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.32      0.50      0.39       241\n",
            "weighted avg       0.49      0.76      0.59       241\n",
            "\n",
            "Iteration: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      1.00      0.78       183\n",
            "       FAVOR       0.00      0.00      0.00        58\n",
            "\n",
            "   micro avg       0.64      0.76      0.70       241\n",
            "   macro avg       0.32      0.50      0.39       241\n",
            "weighted avg       0.49      0.76      0.60       241\n",
            "\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.58      0.64       183\n",
            "       FAVOR       0.26      0.59      0.36        58\n",
            "\n",
            "   micro avg       0.50      0.59      0.54       241\n",
            "   macro avg       0.48      0.59      0.50       241\n",
            "weighted avg       0.60      0.59      0.57       241\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.68      0.69       183\n",
            "       FAVOR       0.27      0.41      0.32        58\n",
            "\n",
            "   micro avg       0.55      0.62      0.58       241\n",
            "   macro avg       0.48      0.55      0.51       241\n",
            "weighted avg       0.59      0.62      0.60       241\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.56      0.62       183\n",
            "       FAVOR       0.28      0.57      0.37        58\n",
            "\n",
            "   micro avg       0.51      0.56      0.53       241\n",
            "   macro avg       0.49      0.56      0.50       241\n",
            "weighted avg       0.60      0.56      0.56       241\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.60      0.65       183\n",
            "       FAVOR       0.28      0.48      0.35        58\n",
            "\n",
            "   micro avg       0.54      0.57      0.55       241\n",
            "   macro avg       0.49      0.54      0.50       241\n",
            "weighted avg       0.60      0.57      0.58       241\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.63      0.67       183\n",
            "       FAVOR       0.31      0.50      0.38        58\n",
            "\n",
            "   micro avg       0.56      0.60      0.58       241\n",
            "   macro avg       0.51      0.56      0.52       241\n",
            "weighted avg       0.62      0.60      0.60       241\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.65      0.68       183\n",
            "       FAVOR       0.32      0.52      0.40        58\n",
            "\n",
            "   micro avg       0.57      0.62      0.59       241\n",
            "   macro avg       0.52      0.58      0.54       241\n",
            "weighted avg       0.62      0.62      0.61       241\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.61      0.66       183\n",
            "       FAVOR       0.32      0.52      0.40        58\n",
            "\n",
            "   micro avg       0.57      0.59      0.58       241\n",
            "   macro avg       0.52      0.56      0.53       241\n",
            "weighted avg       0.63      0.59      0.60       241\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.63      0.67       183\n",
            "       FAVOR       0.35      0.57      0.43        58\n",
            "\n",
            "   micro avg       0.58      0.62      0.60       241\n",
            "   macro avg       0.53      0.60      0.55       241\n",
            "weighted avg       0.63      0.62      0.62       241\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.66      0.69       183\n",
            "       FAVOR       0.34      0.55      0.42        58\n",
            "\n",
            "   micro avg       0.58      0.63      0.61       241\n",
            "   macro avg       0.53      0.60      0.55       241\n",
            "weighted avg       0.63      0.63      0.62       241\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.64      0.68       183\n",
            "       FAVOR       0.38      0.57      0.45        58\n",
            "\n",
            "   micro avg       0.60      0.63      0.61       241\n",
            "   macro avg       0.55      0.61      0.57       241\n",
            "weighted avg       0.64      0.63      0.63       241\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.60      0.66       183\n",
            "       FAVOR       0.36      0.64      0.46        58\n",
            "\n",
            "   micro avg       0.58      0.61      0.59       241\n",
            "   macro avg       0.55      0.62      0.56       241\n",
            "weighted avg       0.65      0.61      0.61       241\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.63      0.68       183\n",
            "       FAVOR       0.38      0.64      0.47        58\n",
            "\n",
            "   micro avg       0.60      0.63      0.62       241\n",
            "   macro avg       0.56      0.63      0.58       241\n",
            "weighted avg       0.65      0.63      0.63       241\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.63      0.68       183\n",
            "       FAVOR       0.39      0.66      0.49        58\n",
            "\n",
            "   micro avg       0.61      0.63      0.62       241\n",
            "   macro avg       0.57      0.64      0.59       241\n",
            "weighted avg       0.66      0.63      0.63       241\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.60      0.66       183\n",
            "       FAVOR       0.35      0.67      0.46        58\n",
            "\n",
            "   micro avg       0.57      0.61      0.59       241\n",
            "   macro avg       0.55      0.63      0.56       241\n",
            "weighted avg       0.64      0.61      0.61       241\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.60      0.65       183\n",
            "       FAVOR       0.35      0.64      0.45        58\n",
            "\n",
            "   micro avg       0.57      0.61      0.59       241\n",
            "   macro avg       0.54      0.62      0.55       241\n",
            "weighted avg       0.63      0.61      0.60       241\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.57      0.64       183\n",
            "       FAVOR       0.33      0.64      0.44        58\n",
            "\n",
            "   micro avg       0.55      0.59      0.57       241\n",
            "   macro avg       0.53      0.61      0.54       241\n",
            "weighted avg       0.63      0.59      0.59       241\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.62      0.66       183\n",
            "       FAVOR       0.35      0.60      0.44        58\n",
            "\n",
            "   micro avg       0.57      0.61      0.59       241\n",
            "   macro avg       0.53      0.61      0.55       241\n",
            "weighted avg       0.62      0.61      0.61       241\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.60      0.65       183\n",
            "       FAVOR       0.35      0.62      0.44        58\n",
            "\n",
            "   micro avg       0.56      0.61      0.58       241\n",
            "   macro avg       0.53      0.61      0.55       241\n",
            "weighted avg       0.62      0.61      0.60       241\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FRn1cgfOZVqi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23ddfb6c-a258-44fa-94ec-9f932ffbc019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: sometiimes you just feel like punching a feminist in the face SemST\n",
            "Gold Label:AGAINST\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.42418912053108215, 'FAVOR': 0.3536691665649414, 'NONE': 0.22214169800281525}\n",
            "=======================================\n"
          ]
        }
      ],
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_feminism\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yn8oL27D9zx"
      },
      "source": [
        "# ASSIGNMENTS\n",
        "\n",
        "1. TODO Train the classifiers for the other 4 targets in the Stance SemEval 2016 dataset.\n",
        "\n",
        "2. TODO Reuse the above code to train a new classifier for fake news using the celebrity and the fake news datasets: \n",
        "\n",
        "  Data: \"/content/drive/My Drive/Colab Notebooks/2023-ILTAPP/datasets/fake_rada\"\n",
        "\n",
        "  2.1 HINT: You need to (i) load the data into a pandas dataframe; (ii) modify the labels from the converter and training functions.\n",
        "\n",
        "  2.2 HINT:Once you have a pandas dataframe, it is easy to split the data into 80% for training and 20% for testing.\n",
        "\n",
        "3. TODO Try the different spacy language models to see the difference in performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS4ZPfR8zUa1"
      },
      "source": [
        "1. TODO Train the classifiers for the other 4 targets in the Stance SemEval 2016 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Ycpm4L03zQcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d18477-6756-4b2b-885c-d681218417de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Atheism', 'Legalization of Abortion', 'Hillary Clinton', 'Climate Change is a Real Concern', 'Feminist Movement']\n"
          ]
        }
      ],
      "source": [
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.TODO Train the classifiers for the other 4 targets in the Stance SemEval 2016 dataset"
      ],
      "metadata": {
        "id": "02SpXJlC4aqI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKpWwJB12n4y"
      },
      "source": [
        "#Climate_change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqF6tfWC2h69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24f7ce0-6e6d-48d9-ce50-e6196bf1f3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAVOR      212\n",
            "NONE       168\n",
            "AGAINST     15\n",
            "Name: Stance, dtype: int64\n",
            "[('We cant deny it, its really happening.  SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('RT cderworiz: Timelines are short. Strategy must be in place by climate change conference in Paris by December. ableg SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('SO EXCITING! Meaningful climate change action is on the way! abpoli GHG SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('Delivering good jobs for Albertans, maintaining a stable economy & meeting climate change strategy. Good goals. abpoli GHG SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('davidswann says he wants carbon fund to be spent on public transportation and renewable energy. ejlive ableg SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('Questions about the LancetGH report?  asklancet tweet chat happening now! actonclimate ClimateHealth SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('We are working to elect climate-friendly governments across North America FeelTheBern NDP LPC GPC BQ HARPERPAC.CA SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('ChrisLeinberger :  change from drivable to walkable = 1 benefit 4 APANE2015 SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('Our amazing ESS15 panel gkremen, SuffolkBuilds, maxfieldweiss & Oakland on how to prepare & protect BayArea region from SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('The Climate Change people are disgusting assholes. Money transfer scheme for elite. May you rot.   SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}})]\n",
            "395\n",
            "FAVOR      123\n",
            "NONE        35\n",
            "AGAINST     11\n",
            "Name: Stance, dtype: int64\n",
            "169\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Climate Change is a Real Concern.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Climate Change is a Real Concern.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "id": "HOetjczKKIBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7e1753b-7cef-421f-c6b4-b44b8850e476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.75      0.98      0.85       123\n",
            "\n",
            "   micro avg       0.75      0.90      0.82       134\n",
            "   macro avg       0.37      0.49      0.42       134\n",
            "weighted avg       0.69      0.90      0.78       134\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.75      0.98      0.85       123\n",
            "\n",
            "   micro avg       0.75      0.90      0.82       134\n",
            "   macro avg       0.38      0.49      0.43       134\n",
            "weighted avg       0.69      0.90      0.78       134\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.76      0.98      0.86       123\n",
            "\n",
            "   micro avg       0.76      0.90      0.82       134\n",
            "   macro avg       0.38      0.49      0.43       134\n",
            "weighted avg       0.69      0.90      0.78       134\n",
            "\n",
            "Iteration: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.75      0.98      0.85       123\n",
            "\n",
            "   micro avg       0.75      0.90      0.82       134\n",
            "   macro avg       0.38      0.49      0.43       134\n",
            "weighted avg       0.69      0.90      0.78       134\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.76      0.97      0.85       123\n",
            "\n",
            "   micro avg       0.76      0.89      0.82       134\n",
            "   macro avg       0.38      0.48      0.43       134\n",
            "weighted avg       0.70      0.89      0.78       134\n",
            "\n",
            "Iteration: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.76      0.97      0.85       123\n",
            "\n",
            "   micro avg       0.76      0.89      0.82       134\n",
            "   macro avg       0.38      0.48      0.43       134\n",
            "weighted avg       0.70      0.89      0.78       134\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.76      0.97      0.85       123\n",
            "\n",
            "   micro avg       0.76      0.89      0.82       134\n",
            "   macro avg       0.38      0.48      0.43       134\n",
            "weighted avg       0.70      0.89      0.78       134\n",
            "\n",
            "Iteration: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.76      0.96      0.85       123\n",
            "\n",
            "   micro avg       0.76      0.88      0.82       134\n",
            "   macro avg       0.38      0.48      0.42       134\n",
            "weighted avg       0.70      0.88      0.78       134\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.96      0.86       123\n",
            "\n",
            "   micro avg       0.77      0.88      0.82       134\n",
            "   macro avg       0.39      0.48      0.43       134\n",
            "weighted avg       0.71      0.88      0.78       134\n",
            "\n",
            "Iteration: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.94      0.85       123\n",
            "\n",
            "   micro avg       0.77      0.87      0.81       134\n",
            "   macro avg       0.38      0.47      0.42       134\n",
            "weighted avg       0.71      0.87      0.78       134\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.93      0.84       123\n",
            "\n",
            "   micro avg       0.77      0.86      0.81       134\n",
            "   macro avg       0.38      0.47      0.42       134\n",
            "weighted avg       0.70      0.86      0.77       134\n",
            "\n",
            "Iteration: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.93      0.84       123\n",
            "\n",
            "   micro avg       0.77      0.86      0.81       134\n",
            "   macro avg       0.38      0.47      0.42       134\n",
            "weighted avg       0.70      0.86      0.77       134\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.93      0.84       123\n",
            "\n",
            "   micro avg       0.77      0.85      0.81       134\n",
            "   macro avg       0.39      0.46      0.42       134\n",
            "weighted avg       0.71      0.85      0.77       134\n",
            "\n",
            "Iteration: 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.91      0.84       123\n",
            "\n",
            "   micro avg       0.77      0.84      0.80       134\n",
            "   macro avg       0.39      0.46      0.42       134\n",
            "weighted avg       0.71      0.84      0.77       134\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.90      0.83       123\n",
            "\n",
            "   micro avg       0.77      0.83      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.83      0.76       134\n",
            "\n",
            "Iteration: 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.90      0.83       123\n",
            "\n",
            "   micro avg       0.77      0.83      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.83      0.76       134\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.78      0.90      0.83       123\n",
            "\n",
            "   micro avg       0.78      0.83      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.83      0.77       134\n",
            "\n",
            "Iteration: 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.89      0.83       123\n",
            "\n",
            "   micro avg       0.77      0.82      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.82      0.76       134\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.89      0.83       123\n",
            "\n",
            "   micro avg       0.77      0.82      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.82      0.76       134\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.77      0.89      0.83       123\n",
            "\n",
            "   micro avg       0.77      0.82      0.80       134\n",
            "   macro avg       0.39      0.45      0.42       134\n",
            "weighted avg       0.71      0.82      0.76       134\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_cl50Qy3a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dcde0a6-6ee7-4c6c-f013-e137a73cee4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.73      1.00      0.84       123\n",
            "\n",
            "   micro avg       0.73      0.92      0.81       134\n",
            "   macro avg       0.36      0.50      0.42       134\n",
            "weighted avg       0.67      0.92      0.77       134\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.78      0.38      0.51       123\n",
            "\n",
            "   micro avg       0.78      0.35      0.48       134\n",
            "   macro avg       0.39      0.19      0.26       134\n",
            "weighted avg       0.72      0.35      0.47       134\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.73      1.00      0.85       123\n",
            "\n",
            "   micro avg       0.73      0.92      0.81       134\n",
            "   macro avg       0.37      0.50      0.42       134\n",
            "weighted avg       0.67      0.92      0.78       134\n",
            "\n",
            "Iteration: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.75      0.96      0.84       123\n",
            "\n",
            "   micro avg       0.75      0.88      0.81       134\n",
            "   macro avg       0.38      0.48      0.42       134\n",
            "weighted avg       0.69      0.88      0.77       134\n",
            "\n",
            "Iteration: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.84      0.82       123\n",
            "\n",
            "   micro avg       0.80      0.77      0.78       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.77      0.75       134\n",
            "\n",
            "Iteration: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.81      0.85      0.83       123\n",
            "\n",
            "   micro avg       0.81      0.78      0.79       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.74      0.78      0.76       134\n",
            "\n",
            "Iteration: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.81      0.80      0.80       123\n",
            "\n",
            "   micro avg       0.81      0.73      0.77       134\n",
            "   macro avg       0.40      0.40      0.40       134\n",
            "weighted avg       0.74      0.73      0.74       134\n",
            "\n",
            "Iteration: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.80      0.80       123\n",
            "\n",
            "   micro avg       0.80      0.74      0.77       134\n",
            "   macro avg       0.40      0.40      0.40       134\n",
            "weighted avg       0.74      0.74      0.74       134\n",
            "\n",
            "Iteration: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.81      0.82      0.82       123\n",
            "\n",
            "   micro avg       0.81      0.75      0.78       134\n",
            "   macro avg       0.41      0.41      0.41       134\n",
            "weighted avg       0.75      0.75      0.75       134\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.85      0.82       123\n",
            "\n",
            "   micro avg       0.79      0.78      0.78       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.78      0.75       134\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.84      0.82       123\n",
            "\n",
            "   micro avg       0.79      0.77      0.78       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.74      0.77      0.75       134\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.83      0.82      0.82       123\n",
            "\n",
            "   micro avg       0.81      0.75      0.78       134\n",
            "   macro avg       0.41      0.41      0.41       134\n",
            "weighted avg       0.76      0.75      0.76       134\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.84      0.80      0.82       123\n",
            "\n",
            "   micro avg       0.82      0.74      0.78       134\n",
            "   macro avg       0.42      0.40      0.41       134\n",
            "weighted avg       0.77      0.74      0.75       134\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.82      0.83      0.82       123\n",
            "\n",
            "   micro avg       0.80      0.76      0.78       134\n",
            "   macro avg       0.41      0.41      0.41       134\n",
            "weighted avg       0.75      0.76      0.76       134\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.82      0.80      0.81       123\n",
            "\n",
            "   micro avg       0.81      0.73      0.77       134\n",
            "   macro avg       0.41      0.40      0.40       134\n",
            "weighted avg       0.76      0.73      0.74       134\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.79      0.84      0.81       123\n",
            "\n",
            "   micro avg       0.77      0.77      0.77       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.77      0.75       134\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.79      0.85      0.82       123\n",
            "\n",
            "   micro avg       0.78      0.78      0.78       134\n",
            "   macro avg       0.39      0.43      0.41       134\n",
            "weighted avg       0.72      0.78      0.75       134\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.79      0.85      0.82       123\n",
            "\n",
            "   micro avg       0.78      0.78      0.78       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.78      0.75       134\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.84      0.82       123\n",
            "\n",
            "   micro avg       0.78      0.77      0.77       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.77      0.75       134\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.00      0.00      0.00        11\n",
            "       FAVOR       0.80      0.84      0.82       123\n",
            "\n",
            "   micro avg       0.78      0.77      0.77       134\n",
            "   macro avg       0.40      0.42      0.41       134\n",
            "weighted avg       0.73      0.77      0.75       134\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_climate_change\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "lIdIlHPQLa1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd263f3f-0990-4abf-b26b-89ffb42d7ab5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Trump's travel ban still out of favor with court A federal appellate court on Thursday refused to reinstate Trump's travel ban. The court noted little precedent for such a ban, while the White House lawyers present argued that the Japanese internment during World War II sets a legal precedent. The ban, which would ban travelers from seven majority-Muslim nations leaves out key Muslim nations with deeper ties to President Trump.\n",
            "Gold Label:fake\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.002197574358433485, 'FAVOR': 0.7536566257476807, 'NONE': 0.24414588510990143}\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDZoLQst3yOA"
      },
      "source": [
        "#Atheism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJZM_JC-38C1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211a2229-4c5b-4aed-c60d-24c34626d230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGAINST    304\n",
            "NONE       117\n",
            "FAVOR       92\n",
            "Name: Stance, dtype: int64\n",
            "[('dear lord thank u for all of ur blessings forgive my sins lord give me strength and energy for this busy day ahead blessed hope SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Blessed are the peacemakers, for they shall be called children of God. Matthew 5:9 scripture peace SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('I am not conformed to this world. I am transformed by the renewing of my mind. ISpeakLife God 2014 SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Salah should be prayed with focus and understanding. Allah warns against lazy prayers done just for show Surah Al-Maoon 107:4-6 SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('And stay in your houses and do not display yourselves like that of the times of ignorance.\" [Quran 33:33].islam SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('If we are unsure whether something is halal or haram, we should leave it - this will safeguard our deen rule SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Papa God, i pray that You shower me with more patience.  worththewait SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"Now that the SCOC has ruled Canadians have freedom from religion, can someone tell Harper to dummy his 'god bless Canada'. cdnpoli SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('Wow, unsubstantiated claims about spooks. Remember whe I said there were gullible people? jvx242 SemST', {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}}), ('RT \"...That kind of modesty is too arrogant for me.\"Christopher Hitchens 2/2\" Funny SemST', {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}})]\n",
            "513\n",
            "AGAINST    160\n",
            "FAVOR       32\n",
            "NONE        28\n",
            "Name: Stance, dtype: int64\n",
            "220\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Atheism.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Atheism.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "id": "ycFlFpTALqiS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffba4350-cd36-4781-f4c4-774f12d2309d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       1.00      0.03      0.06        32\n",
            "\n",
            "   micro avg       0.73      0.84      0.78       192\n",
            "   macro avg       0.87      0.52      0.45       192\n",
            "weighted avg       0.78      0.84      0.71       192\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.99      0.84       160\n",
            "       FAVOR       0.50      0.03      0.06        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.62      0.51      0.45       192\n",
            "weighted avg       0.69      0.83      0.71       192\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.99      0.85       160\n",
            "       FAVOR       0.50      0.03      0.06        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.62      0.51      0.45       192\n",
            "weighted avg       0.70      0.83      0.71       192\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.99      0.84       160\n",
            "       FAVOR       0.33      0.03      0.06        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.54      0.51      0.45       192\n",
            "weighted avg       0.67      0.83      0.71       192\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.97      0.84       160\n",
            "       FAVOR       0.40      0.06      0.11        32\n",
            "\n",
            "   micro avg       0.73      0.82      0.77       192\n",
            "   macro avg       0.57      0.52      0.47       192\n",
            "weighted avg       0.68      0.82      0.72       192\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.97      0.84       160\n",
            "       FAVOR       0.33      0.06      0.11        32\n",
            "\n",
            "   micro avg       0.73      0.82      0.77       192\n",
            "   macro avg       0.54      0.52      0.47       192\n",
            "weighted avg       0.67      0.82      0.72       192\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.96      0.84       160\n",
            "       FAVOR       0.29      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.73      0.81      0.77       192\n",
            "   macro avg       0.51      0.51      0.47       192\n",
            "weighted avg       0.66      0.81      0.71       192\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.96      0.83       160\n",
            "       FAVOR       0.29      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.72      0.81      0.76       192\n",
            "   macro avg       0.51      0.51      0.47       192\n",
            "weighted avg       0.66      0.81      0.71       192\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.96      0.84       160\n",
            "       FAVOR       0.29      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.73      0.81      0.77       192\n",
            "   macro avg       0.51      0.51      0.47       192\n",
            "weighted avg       0.67      0.81      0.71       192\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.96      0.84       160\n",
            "       FAVOR       0.29      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.73      0.81      0.77       192\n",
            "   macro avg       0.51      0.51      0.47       192\n",
            "weighted avg       0.67      0.81      0.71       192\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.96      0.84       160\n",
            "       FAVOR       0.29      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.73      0.81      0.77       192\n",
            "   macro avg       0.51      0.51      0.47       192\n",
            "weighted avg       0.67      0.81      0.71       192\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.95      0.84       160\n",
            "       FAVOR       0.25      0.06      0.10        32\n",
            "\n",
            "   micro avg       0.73      0.80      0.76       192\n",
            "   macro avg       0.50      0.51      0.47       192\n",
            "weighted avg       0.66      0.80      0.71       192\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZv0REKH3xph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f07d873c-11f1-4bfd-a2f0-aad09a0e44fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      1.00      0.84       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.73      0.83      0.78       192\n",
            "   macro avg       0.36      0.50      0.42       192\n",
            "weighted avg       0.61      0.83      0.70       192\n",
            "\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.90      0.83       160\n",
            "       FAVOR       0.20      0.03      0.05        32\n",
            "\n",
            "   micro avg       0.75      0.76      0.75       192\n",
            "   macro avg       0.48      0.47      0.44       192\n",
            "weighted avg       0.67      0.76      0.70       192\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.81      0.83      0.82       160\n",
            "       FAVOR       0.33      0.12      0.18        32\n",
            "\n",
            "   micro avg       0.77      0.71      0.74       192\n",
            "   macro avg       0.57      0.48      0.50       192\n",
            "weighted avg       0.73      0.71      0.71       192\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.84      0.82       160\n",
            "       FAVOR       0.50      0.12      0.20        32\n",
            "\n",
            "   micro avg       0.78      0.72      0.75       192\n",
            "   macro avg       0.65      0.48      0.51       192\n",
            "weighted avg       0.75      0.72      0.71       192\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.84      0.75      0.79       160\n",
            "       FAVOR       0.34      0.44      0.38        32\n",
            "\n",
            "   micro avg       0.73      0.70      0.71       192\n",
            "   macro avg       0.59      0.59      0.59       192\n",
            "weighted avg       0.76      0.70      0.72       192\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.79      0.80       160\n",
            "       FAVOR       0.00      0.00      0.00        32\n",
            "\n",
            "   micro avg       0.81      0.66      0.72       192\n",
            "   macro avg       0.41      0.39      0.40       192\n",
            "weighted avg       0.68      0.66      0.67       192\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.79      0.79       160\n",
            "       FAVOR       0.36      0.28      0.32        32\n",
            "\n",
            "   micro avg       0.74      0.70      0.72       192\n",
            "   macro avg       0.58      0.53      0.56       192\n",
            "weighted avg       0.73      0.70      0.72       192\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.83      0.76      0.79       160\n",
            "       FAVOR       0.43      0.28      0.34        32\n",
            "\n",
            "   micro avg       0.78      0.68      0.73       192\n",
            "   macro avg       0.63      0.52      0.57       192\n",
            "weighted avg       0.76      0.68      0.72       192\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.77      0.79       160\n",
            "       FAVOR       0.33      0.31      0.32        32\n",
            "\n",
            "   micro avg       0.74      0.69      0.72       192\n",
            "   macro avg       0.58      0.54      0.56       192\n",
            "weighted avg       0.74      0.69      0.72       192\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.85      0.76      0.80       160\n",
            "       FAVOR       0.33      0.34      0.34        32\n",
            "\n",
            "   micro avg       0.75      0.69      0.72       192\n",
            "   macro avg       0.59      0.55      0.57       192\n",
            "weighted avg       0.76      0.69      0.73       192\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.82      0.80      0.81       160\n",
            "       FAVOR       0.36      0.31      0.33        32\n",
            "\n",
            "   micro avg       0.75      0.72      0.73       192\n",
            "   macro avg       0.59      0.56      0.57       192\n",
            "weighted avg       0.74      0.72      0.73       192\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.81      0.79      0.80       160\n",
            "       FAVOR       0.36      0.38      0.37        32\n",
            "\n",
            "   micro avg       0.74      0.72      0.73       192\n",
            "   macro avg       0.59      0.58      0.59       192\n",
            "weighted avg       0.74      0.72      0.73       192\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.79      0.79       160\n",
            "       FAVOR       0.31      0.28      0.30        32\n",
            "\n",
            "   micro avg       0.73      0.70      0.71       192\n",
            "   macro avg       0.56      0.53      0.55       192\n",
            "weighted avg       0.72      0.70      0.71       192\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.81      0.78      0.79       160\n",
            "       FAVOR       0.34      0.34      0.34        32\n",
            "\n",
            "   micro avg       0.73      0.70      0.72       192\n",
            "   macro avg       0.58      0.56      0.57       192\n",
            "weighted avg       0.73      0.70      0.72       192\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.76      0.78       160\n",
            "       FAVOR       0.29      0.28      0.29        32\n",
            "\n",
            "   micro avg       0.71      0.68      0.70       192\n",
            "   macro avg       0.54      0.52      0.53       192\n",
            "weighted avg       0.71      0.68      0.70       192\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.77      0.78       160\n",
            "       FAVOR       0.29      0.28      0.29        32\n",
            "\n",
            "   micro avg       0.71      0.69      0.70       192\n",
            "   macro avg       0.54      0.53      0.53       192\n",
            "weighted avg       0.71      0.69      0.70       192\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.80      0.76      0.78       160\n",
            "       FAVOR       0.29      0.28      0.29        32\n",
            "\n",
            "   micro avg       0.71      0.68      0.70       192\n",
            "   macro avg       0.55      0.52      0.53       192\n",
            "weighted avg       0.72      0.68      0.70       192\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.81      0.76      0.78       160\n",
            "       FAVOR       0.29      0.28      0.29        32\n",
            "\n",
            "   micro avg       0.72      0.68      0.70       192\n",
            "   macro avg       0.55      0.52      0.53       192\n",
            "weighted avg       0.72      0.68      0.70       192\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.81      0.76      0.78       160\n",
            "       FAVOR       0.30      0.28      0.29        32\n",
            "\n",
            "   micro avg       0.72      0.68      0.70       192\n",
            "   macro avg       0.55      0.52      0.54       192\n",
            "weighted avg       0.72      0.68      0.70       192\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_Atheism\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "Nk-XF1JpM9o7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07d1786-ea48-4672-d742-44376bcda53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: If only dreams were real, now it's gone. SingleBecause getonyourfeet SemST\n",
            "Gold Label:AGAINST\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.09605187922716141, 'FAVOR': 0.55244380235672, 'NONE': 0.3515043556690216}\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PS7BBN94bre"
      },
      "source": [
        "#Legalization of abortion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKCCCS5C4lSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f75b15-c92e-4610-ec1a-a02144721d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGAINST    355\n",
            "NONE       177\n",
            "FAVOR      121\n",
            "Name: Stance, dtype: int64\n",
            "[('Just laid down the law on abortion in my bioethics class. Catholic SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"tooprettyclub Are you OK with GOP males telling you what you can and can't do with your own body? SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"If you don't want your kid, put it up for adoption. sorrynotsorry SemST\", {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('RedAlert -there should be a \"stigma\" to butchering pre-born children - its a horrendous crime against humanity.  murder SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"But isn't that the problem then. Not enough faith. gaystapo socialism SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}}), ('Life is our first and most basic human right. SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"Rise & Shine its a new day & you're alive. Thank God 4 another day of precious life. Christian Catholic TeamJesus SemST\", {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"Lmao my school thinks giving women the right to an abortion is against feminism. They don't know feminism wtf SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('AsaSoltan putting abortion in with choices for women just won my heart over. Yaaaaaas! shahs SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('Last meeting of the year tonight! 7:00 pm in Case Hall room 334A. Come one come all! Pizza and pop will be provided! SemST', {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}})]\n",
            "653\n",
            "AGAINST    189\n",
            "FAVOR       46\n",
            "NONE        45\n",
            "Name: Stance, dtype: int64\n",
            "280\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Legalization of Abortion.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Legalization of Abortion.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kPP78r95IpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ead21e9-b064-4be2-a8c0-8129ce5a774b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.95      0.79       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.76      0.72       235\n",
            "   macro avg       0.34      0.47      0.40       235\n",
            "weighted avg       0.55      0.76      0.64       235\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.75      0.74       189\n",
            "       FAVOR       0.56      0.39      0.46        46\n",
            "\n",
            "   micro avg       0.71      0.68      0.69       235\n",
            "   macro avg       0.65      0.57      0.60       235\n",
            "weighted avg       0.70      0.68      0.68       235\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.70      0.72       189\n",
            "       FAVOR       0.59      0.50      0.54        46\n",
            "\n",
            "   micro avg       0.72      0.66      0.69       235\n",
            "   macro avg       0.67      0.60      0.63       235\n",
            "weighted avg       0.72      0.66      0.69       235\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.68      0.71       189\n",
            "       FAVOR       0.49      0.48      0.48        46\n",
            "\n",
            "   micro avg       0.69      0.64      0.66       235\n",
            "   macro avg       0.61      0.58      0.60       235\n",
            "weighted avg       0.69      0.64      0.66       235\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.55      0.64       189\n",
            "       FAVOR       0.44      0.57      0.50        46\n",
            "\n",
            "   micro avg       0.67      0.55      0.60       235\n",
            "   macro avg       0.60      0.56      0.57       235\n",
            "weighted avg       0.70      0.55      0.61       235\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.77      0.57      0.65       189\n",
            "       FAVOR       0.43      0.63      0.51        46\n",
            "\n",
            "   micro avg       0.66      0.58      0.62       235\n",
            "   macro avg       0.60      0.60      0.58       235\n",
            "weighted avg       0.70      0.58      0.63       235\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.59      0.66       189\n",
            "       FAVOR       0.42      0.54      0.48        46\n",
            "\n",
            "   micro avg       0.65      0.58      0.62       235\n",
            "   macro avg       0.58      0.57      0.57       235\n",
            "weighted avg       0.68      0.58      0.62       235\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.60      0.66       189\n",
            "       FAVOR       0.46      0.52      0.49        46\n",
            "\n",
            "   micro avg       0.67      0.59      0.62       235\n",
            "   macro avg       0.60      0.56      0.58       235\n",
            "weighted avg       0.68      0.59      0.63       235\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.62      0.68       189\n",
            "       FAVOR       0.47      0.52      0.49        46\n",
            "\n",
            "   micro avg       0.68      0.60      0.64       235\n",
            "   macro avg       0.61      0.57      0.59       235\n",
            "weighted avg       0.69      0.60      0.64       235\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.61      0.67       189\n",
            "       FAVOR       0.51      0.52      0.52        46\n",
            "\n",
            "   micro avg       0.68      0.60      0.63       235\n",
            "   macro avg       0.62      0.57      0.59       235\n",
            "weighted avg       0.69      0.60      0.64       235\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.66      0.69       189\n",
            "       FAVOR       0.49      0.48      0.48        46\n",
            "\n",
            "   micro avg       0.68      0.62      0.65       235\n",
            "   macro avg       0.61      0.57      0.59       235\n",
            "weighted avg       0.68      0.62      0.65       235\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.62      0.67       189\n",
            "       FAVOR       0.49      0.50      0.49        46\n",
            "\n",
            "   micro avg       0.68      0.60      0.64       235\n",
            "   macro avg       0.61      0.56      0.58       235\n",
            "weighted avg       0.69      0.60      0.64       235\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.66      0.70       189\n",
            "       FAVOR       0.51      0.48      0.49        46\n",
            "\n",
            "   micro avg       0.70      0.62      0.66       235\n",
            "   macro avg       0.63      0.57      0.60       235\n",
            "weighted avg       0.70      0.62      0.66       235\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.67      0.70       189\n",
            "       FAVOR       0.49      0.48      0.48        46\n",
            "\n",
            "   micro avg       0.69      0.63      0.66       235\n",
            "   macro avg       0.62      0.57      0.59       235\n",
            "weighted avg       0.69      0.63      0.66       235\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.68      0.71       189\n",
            "       FAVOR       0.50      0.48      0.49        46\n",
            "\n",
            "   micro avg       0.70      0.64      0.67       235\n",
            "   macro avg       0.62      0.58      0.60       235\n",
            "weighted avg       0.70      0.64      0.67       235\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.68      0.71       189\n",
            "       FAVOR       0.46      0.50      0.48        46\n",
            "\n",
            "   micro avg       0.68      0.65      0.66       235\n",
            "   macro avg       0.60      0.59      0.60       235\n",
            "weighted avg       0.69      0.65      0.67       235\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.68      0.72       189\n",
            "       FAVOR       0.52      0.50      0.51        46\n",
            "\n",
            "   micro avg       0.71      0.65      0.68       235\n",
            "   macro avg       0.64      0.59      0.61       235\n",
            "weighted avg       0.71      0.65      0.68       235\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.69      0.71       189\n",
            "       FAVOR       0.48      0.48      0.48        46\n",
            "\n",
            "   micro avg       0.68      0.65      0.67       235\n",
            "   macro avg       0.61      0.59      0.60       235\n",
            "weighted avg       0.68      0.65      0.67       235\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "id": "fwpTC-GsNWRa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d582185a-3074-44f5-b858-595f3ba6e3d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.74       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.74       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.74       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.74       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.74       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.99      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.67      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.99      0.80       189\n",
            "       FAVOR       0.50      0.02      0.04        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.59      0.51      0.42       235\n",
            "weighted avg       0.64      0.80      0.66       235\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.97      0.80       189\n",
            "       FAVOR       0.50      0.07      0.12        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.59      0.52      0.46       235\n",
            "weighted avg       0.64      0.80      0.67       235\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.96      0.80       189\n",
            "       FAVOR       0.57      0.09      0.15        46\n",
            "\n",
            "   micro avg       0.68      0.79      0.73       235\n",
            "   macro avg       0.63      0.52      0.48       235\n",
            "weighted avg       0.66      0.79      0.67       235\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.95      0.80       189\n",
            "       FAVOR       0.60      0.13      0.21        46\n",
            "\n",
            "   micro avg       0.69      0.79      0.74       235\n",
            "   macro avg       0.65      0.54      0.51       235\n",
            "weighted avg       0.68      0.79      0.69       235\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.95      0.81       189\n",
            "       FAVOR       0.55      0.13      0.21        46\n",
            "\n",
            "   micro avg       0.70      0.79      0.74       235\n",
            "   macro avg       0.62      0.54      0.51       235\n",
            "weighted avg       0.67      0.79      0.69       235\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.94      0.81       189\n",
            "       FAVOR       0.60      0.20      0.30        46\n",
            "\n",
            "   micro avg       0.70      0.80      0.75       235\n",
            "   macro avg       0.65      0.57      0.55       235\n",
            "weighted avg       0.69      0.80      0.71       235\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.92      0.80       189\n",
            "       FAVOR       0.56      0.20      0.29        46\n",
            "\n",
            "   micro avg       0.70      0.77      0.73       235\n",
            "   macro avg       0.63      0.56      0.54       235\n",
            "weighted avg       0.68      0.77      0.70       235\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.90      0.79       189\n",
            "       FAVOR       0.55      0.24      0.33        46\n",
            "\n",
            "   micro avg       0.70      0.77      0.73       235\n",
            "   macro avg       0.63      0.57      0.56       235\n",
            "weighted avg       0.68      0.77      0.70       235\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.89      0.79       189\n",
            "       FAVOR       0.50      0.24      0.32        46\n",
            "\n",
            "   micro avg       0.69      0.76      0.72       235\n",
            "   macro avg       0.60      0.56      0.56       235\n",
            "weighted avg       0.67      0.76      0.70       235\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.88      0.79       189\n",
            "       FAVOR       0.52      0.26      0.35        46\n",
            "\n",
            "   micro avg       0.69      0.76      0.73       235\n",
            "   macro avg       0.62      0.57      0.57       235\n",
            "weighted avg       0.67      0.76      0.70       235\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.87      0.79       189\n",
            "       FAVOR       0.52      0.28      0.37        46\n",
            "\n",
            "   micro avg       0.70      0.76      0.73       235\n",
            "   macro avg       0.62      0.58      0.58       235\n",
            "weighted avg       0.68      0.76      0.71       235\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.86      0.79       189\n",
            "       FAVOR       0.54      0.30      0.39        46\n",
            "\n",
            "   micro avg       0.71      0.75      0.73       235\n",
            "   macro avg       0.63      0.58      0.59       235\n",
            "weighted avg       0.69      0.75      0.71       235\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.86      0.79       189\n",
            "       FAVOR       0.54      0.30      0.39        46\n",
            "\n",
            "   micro avg       0.70      0.75      0.73       235\n",
            "   macro avg       0.63      0.58      0.59       235\n",
            "weighted avg       0.69      0.75      0.71       235\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ],
      "metadata": {
        "id": "vl-6_eEBNWuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1d26bf-b943-44f5-d108-b7ebc7aaf48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      1.00      0.81       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.68      0.80      0.73       235\n",
            "   macro avg       0.34      0.50      0.40       235\n",
            "weighted avg       0.54      0.80      0.65       235\n",
            "\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.67      0.89      0.77       189\n",
            "       FAVOR       0.00      0.00      0.00        46\n",
            "\n",
            "   micro avg       0.67      0.71      0.69       235\n",
            "   macro avg       0.34      0.44      0.38       235\n",
            "weighted avg       0.54      0.71      0.62       235\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.71      0.72       189\n",
            "       FAVOR       0.50      0.33      0.39        46\n",
            "\n",
            "   micro avg       0.70      0.64      0.67       235\n",
            "   macro avg       0.61      0.52      0.56       235\n",
            "weighted avg       0.68      0.64      0.66       235\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.66      0.70       189\n",
            "       FAVOR       0.42      0.39      0.40        46\n",
            "\n",
            "   micro avg       0.68      0.61      0.64       235\n",
            "   macro avg       0.58      0.53      0.55       235\n",
            "weighted avg       0.68      0.61      0.64       235\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.64      0.69       189\n",
            "       FAVOR       0.45      0.48      0.46        46\n",
            "\n",
            "   micro avg       0.67      0.61      0.64       235\n",
            "   macro avg       0.60      0.56      0.58       235\n",
            "weighted avg       0.68      0.61      0.64       235\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.68      0.71       189\n",
            "       FAVOR       0.42      0.39      0.40        46\n",
            "\n",
            "   micro avg       0.68      0.62      0.65       235\n",
            "   macro avg       0.58      0.53      0.56       235\n",
            "weighted avg       0.68      0.62      0.65       235\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.71      0.72      0.72       189\n",
            "       FAVOR       0.38      0.35      0.36        46\n",
            "\n",
            "   micro avg       0.65      0.65      0.65       235\n",
            "   macro avg       0.55      0.54      0.54       235\n",
            "weighted avg       0.65      0.65      0.65       235\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.69      0.70       189\n",
            "       FAVOR       0.42      0.35      0.38        46\n",
            "\n",
            "   micro avg       0.67      0.62      0.64       235\n",
            "   macro avg       0.57      0.52      0.54       235\n",
            "weighted avg       0.66      0.62      0.64       235\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.72      0.68      0.70       189\n",
            "       FAVOR       0.39      0.41      0.40        46\n",
            "\n",
            "   micro avg       0.65      0.63      0.64       235\n",
            "   macro avg       0.56      0.55      0.55       235\n",
            "weighted avg       0.66      0.63      0.64       235\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.67      0.70       189\n",
            "       FAVOR       0.40      0.41      0.41        46\n",
            "\n",
            "   micro avg       0.67      0.62      0.64       235\n",
            "   macro avg       0.57      0.54      0.55       235\n",
            "weighted avg       0.67      0.62      0.64       235\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.73      0.67      0.70       189\n",
            "       FAVOR       0.45      0.41      0.43        46\n",
            "\n",
            "   micro avg       0.68      0.62      0.65       235\n",
            "   macro avg       0.59      0.54      0.57       235\n",
            "weighted avg       0.68      0.62      0.65       235\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.63      0.68       189\n",
            "       FAVOR       0.39      0.46      0.42        46\n",
            "\n",
            "   micro avg       0.65      0.60      0.62       235\n",
            "   macro avg       0.56      0.55      0.55       235\n",
            "weighted avg       0.67      0.60      0.63       235\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.74      0.65      0.69       189\n",
            "       FAVOR       0.43      0.43      0.43        46\n",
            "\n",
            "   micro avg       0.67      0.61      0.64       235\n",
            "   macro avg       0.58      0.54      0.56       235\n",
            "weighted avg       0.68      0.61      0.64       235\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.66      0.70       189\n",
            "       FAVOR       0.42      0.46      0.44        46\n",
            "\n",
            "   micro avg       0.68      0.62      0.65       235\n",
            "   macro avg       0.59      0.56      0.57       235\n",
            "weighted avg       0.69      0.62      0.65       235\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.68      0.71       189\n",
            "       FAVOR       0.42      0.41      0.42        46\n",
            "\n",
            "   micro avg       0.68      0.63      0.65       235\n",
            "   macro avg       0.59      0.55      0.57       235\n",
            "weighted avg       0.69      0.63      0.66       235\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.69      0.72       189\n",
            "       FAVOR       0.43      0.48      0.45        46\n",
            "\n",
            "   micro avg       0.69      0.65      0.67       235\n",
            "   macro avg       0.60      0.58      0.59       235\n",
            "weighted avg       0.70      0.65      0.67       235\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.76      0.69      0.72       189\n",
            "       FAVOR       0.42      0.43      0.43        46\n",
            "\n",
            "   micro avg       0.68      0.64      0.66       235\n",
            "   macro avg       0.59      0.56      0.57       235\n",
            "weighted avg       0.69      0.64      0.66       235\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.77      0.67      0.72       189\n",
            "       FAVOR       0.42      0.46      0.44        46\n",
            "\n",
            "   micro avg       0.69      0.63      0.66       235\n",
            "   macro avg       0.59      0.56      0.58       235\n",
            "weighted avg       0.70      0.63      0.66       235\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.75      0.68      0.72       189\n",
            "       FAVOR       0.43      0.43      0.43        46\n",
            "\n",
            "   micro avg       0.69      0.63      0.66       235\n",
            "   macro avg       0.59      0.56      0.58       235\n",
            "weighted avg       0.69      0.63      0.66       235\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_legalization_of_abortion\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "9TazX7PxPp6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182fe2b6-e2fd-4c04-8809-8016adf153dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: The government has given no explanation of why the law was changed macedonia HRCtte SemST\n",
            "Gold Label:AGAINST\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.12442812323570251, 'FAVOR': 0.3234978914260864, 'NONE': 0.5520740151405334}\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVntAJKg5bpC"
      },
      "source": [
        "#Hilary_clinton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-BDBCQo5ffS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb85a88-9460-453d-e3e2-252cc19076f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGAINST    393\n",
            "NONE       178\n",
            "FAVOR      118\n",
            "Name: Stance, dtype: int64\n",
            "[('tedcruz And, HandOverTheServer she wiped clean + 30k deleted emails, explains dereliction of duty/lies re Benghazi,etc tcot SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Hillary is our best choice if we truly want to continue being a progressive nation. Ohio SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"TheView I think our country is ready for a female pres, it can't ever be Hillary SemST\", {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"I just gave an unhealthy amount of my hard-earned money away to the big gov't & untrustworthy IRS. WhyImNotVotingForHillary SemST\", {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('PortiaABoulger Thank you for adding me to your list SemST', {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}}), (\"Hillary can not win. Here's hoping the Dems offer a real candidate like Warren. Warren2016 SemST\", {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Respect FOR the law and respect BY the law Yes, needed desperately.  BaltimoreRiots SemST', {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}}), (\"I don't want to be appointed to an Ambassador post. SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 0, 'NONE': 1}}), ('StopHillary2016 HillaryClinton if there was a woman with integrity and honesty I would vote for such as woman president, NO SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('HillaryClinton End lawless ClintonFoundation. Jail Butcher of Benghazi. Arrest rapist BillClinton. HillaryClinton SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}})]\n",
            "689\n",
            "AGAINST    172\n",
            "NONE        78\n",
            "FAVOR       45\n",
            "Name: Stance, dtype: int64\n",
            "295\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Hillary Clinton.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Hillary Clinton.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcAmx4-G7aw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03184d75-77e5-4fc8-89d9-530601b9d833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      0.99      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.59      0.99      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.59      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.47      0.79      0.59       217\n",
            "\n",
            "Iteration: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.60      0.98      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.60      0.78      0.67       217\n",
            "   macro avg       0.30      0.49      0.37       217\n",
            "weighted avg       0.47      0.78      0.59       217\n",
            "\n",
            "Iteration: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.60      0.98      0.75       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.60      0.78      0.68       217\n",
            "   macro avg       0.30      0.49      0.37       217\n",
            "weighted avg       0.48      0.78      0.59       217\n",
            "\n",
            "Iteration: 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.61      0.98      0.75       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.61      0.78      0.68       217\n",
            "   macro avg       0.31      0.49      0.38       217\n",
            "weighted avg       0.48      0.78      0.60       217\n",
            "\n",
            "Iteration: 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.61      0.98      0.75       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.61      0.78      0.69       217\n",
            "   macro avg       0.31      0.49      0.38       217\n",
            "weighted avg       0.49      0.78      0.60       217\n",
            "\n",
            "Iteration: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.61      0.98      0.75       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.61      0.78      0.69       217\n",
            "   macro avg       0.31      0.49      0.38       217\n",
            "weighted avg       0.49      0.78      0.60       217\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.62      0.98      0.76       172\n",
            "       FAVOR       1.00      0.02      0.04        45\n",
            "\n",
            "   micro avg       0.62      0.78      0.69       217\n",
            "   macro avg       0.81      0.50      0.40       217\n",
            "weighted avg       0.70      0.78      0.61       217\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.62      0.97      0.76       172\n",
            "       FAVOR       1.00      0.07      0.12        45\n",
            "\n",
            "   micro avg       0.62      0.78      0.70       217\n",
            "   macro avg       0.81      0.52      0.44       217\n",
            "weighted avg       0.70      0.78      0.63       217\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.63      0.97      0.76       172\n",
            "       FAVOR       1.00      0.07      0.12        45\n",
            "\n",
            "   micro avg       0.63      0.78      0.70       217\n",
            "   macro avg       0.81      0.52      0.44       217\n",
            "weighted avg       0.70      0.78      0.63       217\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.63      0.97      0.76       172\n",
            "       FAVOR       1.00      0.09      0.16        45\n",
            "\n",
            "   micro avg       0.63      0.79      0.70       217\n",
            "   macro avg       0.81      0.53      0.46       217\n",
            "weighted avg       0.70      0.79      0.64       217\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.63      0.97      0.77       172\n",
            "       FAVOR       0.83      0.11      0.20        45\n",
            "\n",
            "   micro avg       0.64      0.79      0.71       217\n",
            "   macro avg       0.73      0.54      0.48       217\n",
            "weighted avg       0.67      0.79      0.65       217\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.63      0.97      0.76       172\n",
            "       FAVOR       0.83      0.11      0.20        45\n",
            "\n",
            "   micro avg       0.64      0.79      0.70       217\n",
            "   macro avg       0.73      0.54      0.48       217\n",
            "weighted avg       0.67      0.79      0.65       217\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.63      0.95      0.76       172\n",
            "       FAVOR       0.62      0.11      0.19        45\n",
            "\n",
            "   micro avg       0.63      0.77      0.69       217\n",
            "   macro avg       0.63      0.53      0.47       217\n",
            "weighted avg       0.63      0.77      0.64       217\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ],
      "metadata": {
        "id": "Ed0JM223QvWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a121599-6d03-4386-838d-0be543a0206c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.58      1.00      0.74       172\n",
            "       FAVOR       0.00      0.00      0.00        45\n",
            "\n",
            "   micro avg       0.58      0.79      0.67       217\n",
            "   macro avg       0.29      0.50      0.37       217\n",
            "weighted avg       0.46      0.79      0.58       217\n",
            "\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.61      0.97      0.75       172\n",
            "       FAVOR       1.00      0.02      0.04        45\n",
            "\n",
            "   micro avg       0.61      0.77      0.68       217\n",
            "   macro avg       0.80      0.50      0.39       217\n",
            "weighted avg       0.69      0.77      0.60       217\n",
            "\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      0.91      0.75       172\n",
            "       FAVOR       1.00      0.11      0.20        45\n",
            "\n",
            "   micro avg       0.64      0.75      0.69       217\n",
            "   macro avg       0.82      0.51      0.47       217\n",
            "weighted avg       0.71      0.75      0.64       217\n",
            "\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.87      0.75       172\n",
            "       FAVOR       0.62      0.22      0.33        45\n",
            "\n",
            "   micro avg       0.66      0.73      0.69       217\n",
            "   macro avg       0.64      0.54      0.54       217\n",
            "weighted avg       0.65      0.73      0.66       217\n",
            "\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.64      0.87      0.74       172\n",
            "       FAVOR       0.62      0.18      0.28        45\n",
            "\n",
            "   micro avg       0.64      0.73      0.68       217\n",
            "   macro avg       0.63      0.52      0.51       217\n",
            "weighted avg       0.64      0.73      0.64       217\n",
            "\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.85      0.74       172\n",
            "       FAVOR       0.57      0.29      0.38        45\n",
            "\n",
            "   micro avg       0.65      0.74      0.69       217\n",
            "   macro avg       0.61      0.57      0.56       217\n",
            "weighted avg       0.64      0.74      0.67       217\n",
            "\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.85      0.76       172\n",
            "       FAVOR       0.57      0.29      0.38        45\n",
            "\n",
            "   micro avg       0.68      0.74      0.70       217\n",
            "   macro avg       0.63      0.57      0.57       217\n",
            "weighted avg       0.66      0.74      0.68       217\n",
            "\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.85      0.77       172\n",
            "       FAVOR       0.50      0.18      0.26        45\n",
            "\n",
            "   micro avg       0.68      0.71      0.70       217\n",
            "   macro avg       0.60      0.52      0.51       217\n",
            "weighted avg       0.66      0.71      0.66       217\n",
            "\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.85      0.76       172\n",
            "       FAVOR       0.54      0.33      0.41        45\n",
            "\n",
            "   micro avg       0.66      0.75      0.70       217\n",
            "   macro avg       0.61      0.59      0.58       217\n",
            "weighted avg       0.65      0.75      0.69       217\n",
            "\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.70      0.84      0.76       172\n",
            "       FAVOR       0.54      0.31      0.39        45\n",
            "\n",
            "   micro avg       0.68      0.73      0.70       217\n",
            "   macro avg       0.62      0.57      0.58       217\n",
            "weighted avg       0.66      0.73      0.68       217\n",
            "\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.69      0.85      0.76       172\n",
            "       FAVOR       0.54      0.31      0.39        45\n",
            "\n",
            "   micro avg       0.68      0.74      0.70       217\n",
            "   macro avg       0.62      0.58      0.58       217\n",
            "weighted avg       0.66      0.74      0.69       217\n",
            "\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.86      0.76       172\n",
            "       FAVOR       0.58      0.31      0.41        45\n",
            "\n",
            "   micro avg       0.67      0.75      0.71       217\n",
            "   macro avg       0.63      0.59      0.58       217\n",
            "weighted avg       0.66      0.75      0.69       217\n",
            "\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.68      0.85      0.76       172\n",
            "       FAVOR       0.56      0.33      0.42        45\n",
            "\n",
            "   micro avg       0.67      0.74      0.70       217\n",
            "   macro avg       0.62      0.59      0.59       217\n",
            "weighted avg       0.66      0.74      0.69       217\n",
            "\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.86      0.75       172\n",
            "       FAVOR       0.57      0.27      0.36        45\n",
            "\n",
            "   micro avg       0.66      0.74      0.69       217\n",
            "   macro avg       0.62      0.56      0.56       217\n",
            "weighted avg       0.64      0.74      0.67       217\n",
            "\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.67      0.85      0.75       172\n",
            "       FAVOR       0.48      0.29      0.36        45\n",
            "\n",
            "   micro avg       0.65      0.73      0.69       217\n",
            "   macro avg       0.57      0.57      0.55       217\n",
            "weighted avg       0.63      0.73      0.67       217\n",
            "\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.65      0.86      0.74       172\n",
            "       FAVOR       0.50      0.27      0.35        45\n",
            "\n",
            "   micro avg       0.64      0.74      0.69       217\n",
            "   macro avg       0.58      0.56      0.55       217\n",
            "weighted avg       0.62      0.74      0.66       217\n",
            "\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.86      0.75       172\n",
            "       FAVOR       0.52      0.29      0.37        45\n",
            "\n",
            "   micro avg       0.64      0.74      0.69       217\n",
            "   macro avg       0.59      0.57      0.56       217\n",
            "weighted avg       0.63      0.74      0.67       217\n",
            "\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.67      0.87      0.75       172\n",
            "       FAVOR       0.47      0.20      0.28        45\n",
            "\n",
            "   micro avg       0.65      0.73      0.69       217\n",
            "   macro avg       0.57      0.53      0.52       217\n",
            "weighted avg       0.63      0.73      0.65       217\n",
            "\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     AGAINST       0.66      0.88      0.76       172\n",
            "       FAVOR       0.55      0.24      0.34        45\n",
            "\n",
            "   micro avg       0.65      0.75      0.70       217\n",
            "   macro avg       0.61      0.56      0.55       217\n",
            "weighted avg       0.64      0.75      0.67       217\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxXiPQvxB4GG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec44fe99-d6e5-4a9a-bdf0-f19179940288"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: BeladonnaRogers Chairmnoomowmow The compliant media allowed themeselves to b herded by a couple of strands of rope? Good sheep! SemST\n",
            "Gold Label:AGAINST\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.06873271614313126, 'FAVOR': 0.5350690484046936, 'NONE': 0.3961983025074005}\n",
            "=======================================\n"
          ]
        }
      ],
      "source": [
        "textcat_ensemble = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_hiliary_clinton\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gz829TZDD_i"
      },
      "source": [
        "#2.TODO Reuse the above code to train a new classifier for fake news using the celebrity and the fake news datasets:\n",
        "\n",
        "Data: \"/content/drive/My Drive/Colab Notebooks/2022-ILTAPP/datasets/fake_rada\"\n",
        "\n",
        "2.1 HINT: You need to (i) load the data into a pandas dataframe; (ii) modify the labels from the converter and training functions.\n",
        "\n",
        "2.2 HINT:Once you have a pandas dataframe, it is easy to split the data into 80% for training and 20% for testing."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Celebrity_daata_set"
      ],
      "metadata": {
        "id": "ap4q_s0NzYjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "S-wjQB2KSCCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87117d8e-1372-428a-8ddf-3ba7454f3556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     label                                               text\n",
            "0    legit  Jennifer Aniston dashes 'Friends' reunion hope...\n",
            "1    legit  This Is What Brad Pitt Has Been Texting Jennif...\n",
            "2    legit  Jennifer Aniston's spokesman denies reports th...\n",
            "3    legit  Jennifer Aniston sparks adoption rumors Before...\n",
            "4    legit  Jennifer Aniston denies she had an affair with...\n",
            "..     ...                                                ...\n",
            "495   fake  Devastated Johnny Depp Begging For Ex-Wife Van...\n",
            "496   fake  New Suicide Fears For Owen Wilson After Dad’s ...\n",
            "497   fake  Did Taylor Swift Leak Her Romance With Joe Alw...\n",
            "498   fake  Is Ryan Seacrest Quitting 'Live'? Ryan Seacres...\n",
            "499   fake  Digital Diva! Inside Caitlyn Jenner’s Secret C...\n",
            "\n",
            "[500 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "'''This function takes in a list of file names and reads in the data in those files using the pandas library. \n",
        "The data is read in as a pandas dataframe with columns \"label\" and \"text\".\n",
        " The function concatenates all the dataframes into one dataframe and returns it.'''\n",
        "\n",
        "def cleaning_of_data(filenames):\n",
        "    text = []\n",
        "    for filename in filenames:\n",
        "        text.append(pd.read_csv(filename, sep='\\t', encoding='utf-8', names=['label', 'text']))\n",
        "    text = pd.concat(text)\n",
        "    return text\n",
        "\n",
        "cleb_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/celebrity_full.tsv\"\n",
        "celeb_data = cleaning_of_data([cleb_file])\n",
        "print(celeb_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "50gworKrSXD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60225b7-d9ba-4534-b965-6b43ec291d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     label                                               text\n",
            "475   fake  Blue Ivy To Play Nurse For Pregnant Mom Beyonc...\n",
            "341   fake  Drake Facing Gay Rumors After Getting Frisky W...\n",
            "361   fake  Leah Remini Opens Up About Her Friendship With...\n",
            "277   fake  Donald Trump and First Lady Melania Keep Separ...\n",
            "49   legit  Here's How Kim Kardashian West, Kanye West, an...\n",
            "..     ...                                                ...\n",
            "99   legit  WATCH: Donald Trump's Ex-Wife Marla Maples Get...\n",
            "191  legit   Kelly Ripa and Ryan Seacrest tear up on air t...\n",
            "442   fake  Apparently Drake Wants to Settle Down With a W...\n",
            "390   fake  Ryan Gosling says he gave up smoking after fil...\n",
            "40   legit  Kylie Jenner Sets the Record Straight About Re...\n",
            "\n",
            "[400 rows x 2 columns]\n",
            "     label                                               text\n",
            "468   fake  FKA Twigs Looks Miserable With Robert Pattinso...\n",
            "492   fake  Victoria Beckham's big fashion guide: Posh Spi...\n",
            "134  legit  Brad Pitt Responds To Rumours He’s Dating Prin...\n",
            "374   fake  Allison Williams’ top-secret wedding revealed ...\n",
            "73   legit  Justin Bieber Asks 'Taylor Swift What Up' in P...\n",
            "..     ...                                                ...\n",
            "76   legit  AMAL CLOONEY IS THE MOST INFLUENTIAL WOMAN IN ...\n",
            "62   legit  David Gest found dead at 62: Liza Minnelli's e...\n",
            "416   fake  Josh Duhamel was over Fergie ‘being a rock sta...\n",
            "10   legit  Jennifer Lopez and Alex Rodriguez are dating, ...\n",
            "36   legit  Drake Cancels Amsterdam Concert (Again) After ...\n",
            "\n",
            "[100 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(celeb_data, test_size=0.2)\n",
        "\n",
        "print(train)\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "RYonvEa5TBbo"
      },
      "outputs": [],
      "source": [
        "#Splitting of the celebrity data set inti train and test\n",
        "train.to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/train_celebrity.tsv\", sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")\n",
        "test.to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/test_celebrity.tsv\", sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "smAdlOPyTpPz"
      },
      "outputs": [],
      "source": [
        "def fake_data_to_spacy(fname):\n",
        "  training_data = pd.read_csv(fname, sep='\\t', encoding='utf-8')\n",
        "  #train_data.dropna(axis = 0, how ='any',inplace=True)\n",
        "  #train_data['Nef um_words_text'] = train_data['text'].apply(lambda x:len(str(x).split())) \n",
        "  #mask = train_data['Num_words_text'] >2\n",
        "  #train_data = train_data[mask]\n",
        "   \n",
        "  train_texts = training_data['text'].tolist()\n",
        "  train_cats = training_data['label'].tolist()\n",
        "  final_train_cats=[]\n",
        "  for cat in train_cats:\n",
        "    cat_list = {}\n",
        "    if cat == 'fake':\n",
        "      cat_list['fake'] =  1\n",
        "      cat_list['legit'] =  0\n",
        "    else:\n",
        "      cat_list['fake'] =  0\n",
        "      cat_list['legit'] =  1\n",
        "    final_train_cats.append(cat_list)\n",
        "    \n",
        "  train_data = list(zip(train_texts, [{\"cats\": cats} for cats in final_train_cats]))\n",
        "  return train_data, train_texts, train_cats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8gjkYJzCT1D2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "445c00d7-d29a-4ead-a5a8-0423fcb6d1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Blue Ivy To Play Nurse For Pregnant Mom Beyoncé When\\xa0Beyoncé\\xa0goes into labor, she’ll have one very special helper by her side: 5-year-old daughter\\xa0Blue Ivy! According to an insider, the superstar and hubby\\xa0Jay Z have agreed to let Blue play nurse when the singer gives birth to twins, which the insider claims will happen via C-section in June “Blue will be one of the first to hold the babies, with help from Jay, of course, and she’ll be responsible for writing down their height and weight,” shares the insider. “She’ll even get to help tie the ID bracelets on their wrists.” Though some might be hesitant to have a child in the operating room, Bey and Jay “want to make Blue feel included in anything related to bringing the twins into the world,” the insider says. “She’s excited — and they don’t want her to be jealous.” Paging Nurse Blue! ', {'cats': {'fake': 1, 'legit': 0}})\n",
            "400\n",
            "100\n"
          ]
        }
      ],
      "source": [
        "training_data, train_texts, train_cats = fake_data_to_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/train_celebrity.tsv')\n",
        "print(training_data[0])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = fake_data_to_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/test_celebrity.tsv')\n",
        "print(len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Sort(sub_li):\n",
        "  # reverse = True (Soresulting_list = list(first_list)rts in Descending  order) \n",
        "  # key is set to sort using second element of  \n",
        "  # sublist lambda has been used \n",
        "  return(sorted(sub_li, key = lambda x: x[1],reverse=True))  \n",
        "\n",
        "# run the predictions on each sentence in the evaluation  dataset, and return the metrics\n",
        "def evaluate(tokenizer, textcat, test_texts, test_cats ):\n",
        "  docs = (tokenizer(text) for text in test_texts)\n",
        "  preds = []\n",
        "  for i, doc in enumerate(textcat.pipe(docs)):\n",
        "  \n",
        "    scores = Sort(doc.cats.items())\n",
        "  \n",
        "    catList=[]\n",
        "    for score in scores:\n",
        "      catList.append(score[0])\n",
        "    preds.append(catList[0])\n",
        "        \n",
        " \n",
        "  labels = ['fake','legit']\n",
        "  print(classification_report(test_cats, preds,labels=labels))"
      ],
      "metadata": {
        "id": "AeXqk8BIJmHX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacy(  train_data, iterations,test_texts,test_cats, model_arch, dropout = 0.3, model=None, init_tok2vec=None):\n",
        "    ''' Train a spacy model, which can be queried against with test data\n",
        "   \n",
        "    train_data : training data in the format of (sentence, {cats: ['fake'|'legit']})\n",
        "    labels : a list of unique annotations\n",
        "    iterations : number of training iterations\n",
        "    dropout : dropout proportion for training\n",
        "    display_freq : number of epochs between logging losses to console\n",
        "    '''\n",
        "    \n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    \n",
        "\n",
        "    # add the text classifier to the pipeline if it doesn't exist\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"textcat\" not in nlp.pipe_names:\n",
        "        textcat = nlp.create_pipe(\n",
        "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": model_arch}\n",
        "        )\n",
        "        nlp.add_pipe(textcat, last=True)\n",
        "        \n",
        "    # otherwise, get it, so we can add labels to it\n",
        "    else:\n",
        "        textcat = nlp.get_pipe(\"textcat\")\n",
        "\n",
        "    # add label to text classifier\n",
        "    textcat.add_label('fake')\n",
        "    textcat.add_label('legit')\n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
        "        optimizer = nlp.begin_training()\n",
        "        if init_tok2vec is not None:\n",
        "            with init_tok2vec.open(\"rb\") as file_:\n",
        "                textcat.model.tok2vec.from_bytes(file_.read())\n",
        "        print(\"Training the model...\")\n",
        "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "        batch_sizes = compounding(16.0, 64.0, 1.5)\n",
        "        for i in range(iterations):\n",
        "            print('Iteration: '+str(i))\n",
        "            start_time = time.process_time()\n",
        "            losses = {}\n",
        "            # batch up the examples using spaCy's minibatch\n",
        "            random.shuffle(train_data)\n",
        "            batches = minibatch(train_data, size=batch_sizes)\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
        "            with textcat.model.use_params(optimizer.averages):\n",
        "                # evaluate on the test data \n",
        "                evaluate(nlp.tokenizer, textcat, test_texts,test_cats)\n",
        "            print ('Elapsed time'+str(time.process_time() - start_time)+  \"seconds\")\n",
        "        with nlp.use_params(optimizer.averages):\n",
        "            #model_name = model_arch + \"_celebrity\"\n",
        "            model_name = model_arch + \"_fakenews\"\n",
        "            filepath = \"/content/drive/MyDrive/NLP_Applications_1/DATA\" + model_name \n",
        "            nlp.to_disk(filepath)\n",
        "    return nlp"
      ],
      "metadata": {
        "id": "JQghWa2pJz8a"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "id": "q3El7-WBysoq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed45e29-f468-49bb-a88f-08fe048d9661"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.00      0.00      0.00        45\n",
            "       legit       0.55      1.00      0.71        55\n",
            "\n",
            "    accuracy                           0.55       100\n",
            "   macro avg       0.28      0.50      0.35       100\n",
            "weighted avg       0.30      0.55      0.39       100\n",
            "\n",
            "Elapsed time3.121349699999996seconds\n",
            "Iteration: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.46      0.84      0.60        45\n",
            "       legit       0.61      0.20      0.30        55\n",
            "\n",
            "    accuracy                           0.49       100\n",
            "   macro avg       0.54      0.52      0.45       100\n",
            "weighted avg       0.54      0.49      0.44       100\n",
            "\n",
            "Elapsed time4.041491268000016seconds\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.63      0.69      0.66        45\n",
            "       legit       0.73      0.67      0.70        55\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.68      0.68      0.68       100\n",
            "weighted avg       0.68      0.68      0.68       100\n",
            "\n",
            "Elapsed time2.712283850999995seconds\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.69      0.65        45\n",
            "       legit       0.72      0.65      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.68      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.39983523799998seconds\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.71      0.66        45\n",
            "       legit       0.73      0.64      0.68        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.68      0.67      0.67       100\n",
            "\n",
            "Elapsed time3.235909308000032seconds\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.69      0.65        45\n",
            "       legit       0.72      0.65      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.68      0.67      0.67       100\n",
            "\n",
            "Elapsed time4.296946191000018seconds\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.69      0.65        45\n",
            "       legit       0.72      0.65      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.68      0.67      0.67       100\n",
            "\n",
            "Elapsed time3.8548459529999946seconds\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.64      0.63        45\n",
            "       legit       0.70      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.66       100\n",
            "   macro avg       0.66      0.66      0.66       100\n",
            "weighted avg       0.66      0.66      0.66       100\n",
            "\n",
            "Elapsed time2.605611587999988seconds\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.65      0.73      0.69        45\n",
            "       legit       0.76      0.67      0.71        55\n",
            "\n",
            "    accuracy                           0.70       100\n",
            "   macro avg       0.70      0.70      0.70       100\n",
            "weighted avg       0.71      0.70      0.70       100\n",
            "\n",
            "Elapsed time2.5043415279999977seconds\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.67      0.65        45\n",
            "       legit       0.71      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.378643387000011seconds\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.64      0.62      0.63        45\n",
            "       legit       0.70      0.71      0.70        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.563910352999983seconds\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.60      0.64      0.62        45\n",
            "       legit       0.69      0.65      0.67        55\n",
            "\n",
            "    accuracy                           0.65       100\n",
            "   macro avg       0.65      0.65      0.65       100\n",
            "weighted avg       0.65      0.65      0.65       100\n",
            "\n",
            "Elapsed time3.951130670999987seconds\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.64      0.63        45\n",
            "       legit       0.70      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.66       100\n",
            "   macro avg       0.66      0.66      0.66       100\n",
            "weighted avg       0.66      0.66      0.66       100\n",
            "\n",
            "Elapsed time2.470944004000046seconds\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.61      0.69      0.65        45\n",
            "       legit       0.71      0.64      0.67        55\n",
            "\n",
            "    accuracy                           0.66       100\n",
            "   macro avg       0.66      0.66      0.66       100\n",
            "weighted avg       0.67      0.66      0.66       100\n",
            "\n",
            "Elapsed time2.2048676109999974seconds\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.64      0.67      0.65        45\n",
            "       legit       0.72      0.69      0.70        55\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.68      0.68      0.68       100\n",
            "weighted avg       0.68      0.68      0.68       100\n",
            "\n",
            "Elapsed time2.1953523909999717seconds\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.64      0.67      0.65        45\n",
            "       legit       0.72      0.69      0.70        55\n",
            "\n",
            "    accuracy                           0.68       100\n",
            "   macro avg       0.68      0.68      0.68       100\n",
            "weighted avg       0.68      0.68      0.68       100\n",
            "\n",
            "Elapsed time2.4354820110000333seconds\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.67      0.65        45\n",
            "       legit       0.71      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time3.684529779999991seconds\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.67      0.65        45\n",
            "       legit       0.71      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.9208401289999983seconds\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.67      0.65        45\n",
            "       legit       0.71      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.3696063120000304seconds\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.67      0.65        45\n",
            "       legit       0.71      0.67      0.69        55\n",
            "\n",
            "    accuracy                           0.67       100\n",
            "   macro avg       0.67      0.67      0.67       100\n",
            "weighted avg       0.67      0.67      0.67       100\n",
            "\n",
            "Elapsed time2.313060885000027seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ],
      "metadata": {
        "id": "KQT7gfkUI2Yu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c88179b5-d943-44f9-a577-018e89989112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.47      1.00      0.64        47\n",
            "       legit       0.00      0.00      0.00        53\n",
            "\n",
            "    accuracy                           0.47       100\n",
            "   macro avg       0.23      0.50      0.32       100\n",
            "weighted avg       0.22      0.47      0.30       100\n",
            "\n",
            "Elapsed time22.04621323699996seconds\n",
            "Iteration: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       1.00      0.06      0.12        47\n",
            "       legit       0.55      1.00      0.71        53\n",
            "\n",
            "    accuracy                           0.56       100\n",
            "   macro avg       0.77      0.53      0.41       100\n",
            "weighted avg       0.76      0.56      0.43       100\n",
            "\n",
            "Elapsed time19.94427032699997seconds\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.65      0.89      0.75        47\n",
            "       legit       0.86      0.57      0.68        53\n",
            "\n",
            "    accuracy                           0.72       100\n",
            "   macro avg       0.75      0.73      0.72       100\n",
            "weighted avg       0.76      0.72      0.71       100\n",
            "\n",
            "Elapsed time21.163961693999966seconds\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.87      0.57      0.69        47\n",
            "       legit       0.71      0.92      0.80        53\n",
            "\n",
            "    accuracy                           0.76       100\n",
            "   macro avg       0.79      0.75      0.75       100\n",
            "weighted avg       0.79      0.76      0.75       100\n",
            "\n",
            "Elapsed time19.675042808seconds\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.70      0.83      0.76        47\n",
            "       legit       0.82      0.68      0.74        53\n",
            "\n",
            "    accuracy                           0.75       100\n",
            "   macro avg       0.76      0.75      0.75       100\n",
            "weighted avg       0.76      0.75      0.75       100\n",
            "\n",
            "Elapsed time19.871688226000003seconds\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.87      0.70      0.78        47\n",
            "       legit       0.77      0.91      0.83        53\n",
            "\n",
            "    accuracy                           0.81       100\n",
            "   macro avg       0.82      0.80      0.81       100\n",
            "weighted avg       0.82      0.81      0.81       100\n",
            "\n",
            "Elapsed time22.50704040300002seconds\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.85      0.70      0.77        47\n",
            "       legit       0.77      0.89      0.82        53\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.81      0.79      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Elapsed time19.869546019999973seconds\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.85      0.70      0.77        47\n",
            "       legit       0.77      0.89      0.82        53\n",
            "\n",
            "    accuracy                           0.80       100\n",
            "   macro avg       0.81      0.79      0.80       100\n",
            "weighted avg       0.81      0.80      0.80       100\n",
            "\n",
            "Elapsed time20.59984701999997seconds\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.76      0.74      0.75        47\n",
            "       legit       0.78      0.79      0.79        53\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.77      0.77      0.77       100\n",
            "weighted avg       0.77      0.77      0.77       100\n",
            "\n",
            "Elapsed time20.559557954000013seconds\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.74      0.74      0.74        47\n",
            "       legit       0.77      0.77      0.77        53\n",
            "\n",
            "    accuracy                           0.76       100\n",
            "   macro avg       0.76      0.76      0.76       100\n",
            "weighted avg       0.76      0.76      0.76       100\n",
            "\n",
            "Elapsed time19.898070769000014seconds\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.84      0.66      0.74        47\n",
            "       legit       0.75      0.89      0.81        53\n",
            "\n",
            "    accuracy                           0.78       100\n",
            "   macro avg       0.79      0.77      0.77       100\n",
            "weighted avg       0.79      0.78      0.78       100\n",
            "\n",
            "Elapsed time21.466770917999952seconds\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.76      0.74      0.75        47\n",
            "       legit       0.78      0.79      0.79        53\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.77      0.77      0.77       100\n",
            "weighted avg       0.77      0.77      0.77       100\n",
            "\n",
            "Elapsed time19.932329106999987seconds\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.85      0.62      0.72        47\n",
            "       legit       0.73      0.91      0.81        53\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.79      0.76      0.76       100\n",
            "weighted avg       0.79      0.77      0.76       100\n",
            "\n",
            "Elapsed time20.669867380000028seconds\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.79      0.66      0.72        47\n",
            "       legit       0.74      0.85      0.79        53\n",
            "\n",
            "    accuracy                           0.76       100\n",
            "   macro avg       0.77      0.75      0.76       100\n",
            "weighted avg       0.76      0.76      0.76       100\n",
            "\n",
            "Elapsed time20.357237025000018seconds\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.78      0.68      0.73        47\n",
            "       legit       0.75      0.83      0.79        53\n",
            "\n",
            "    accuracy                           0.76       100\n",
            "   macro avg       0.76      0.76      0.76       100\n",
            "weighted avg       0.76      0.76      0.76       100\n",
            "\n",
            "Elapsed time19.773310742000035seconds\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.76      0.68      0.72        47\n",
            "       legit       0.74      0.81      0.77        53\n",
            "\n",
            "    accuracy                           0.75       100\n",
            "   macro avg       0.75      0.75      0.75       100\n",
            "weighted avg       0.75      0.75      0.75       100\n",
            "\n",
            "Elapsed time21.21745647599994seconds\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.76      0.68      0.72        47\n",
            "       legit       0.74      0.81      0.77        53\n",
            "\n",
            "    accuracy                           0.75       100\n",
            "   macro avg       0.75      0.75      0.75       100\n",
            "weighted avg       0.75      0.75      0.75       100\n",
            "\n",
            "Elapsed time20.03416804699998seconds\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.73      0.68      0.70        47\n",
            "       legit       0.73      0.77      0.75        53\n",
            "\n",
            "    accuracy                           0.73       100\n",
            "   macro avg       0.73      0.73      0.73       100\n",
            "weighted avg       0.73      0.73      0.73       100\n",
            "\n",
            "Elapsed time22.476187806999974seconds\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.80      0.68      0.74        47\n",
            "       legit       0.75      0.85      0.80        53\n",
            "\n",
            "    accuracy                           0.77       100\n",
            "   macro avg       0.78      0.76      0.77       100\n",
            "weighted avg       0.77      0.77      0.77       100\n",
            "\n",
            "Elapsed time20.722517553999978seconds\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.74      0.68      0.71        47\n",
            "       legit       0.74      0.79      0.76        53\n",
            "\n",
            "    accuracy                           0.74       100\n",
            "   macro avg       0.74      0.74      0.74       100\n",
            "weighted avg       0.74      0.74      0.74       100\n",
            "\n",
            "Elapsed time19.836087955999915seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_celebrity\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "4bFWpTC7wVLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58e09781-f5ea-4236-b558-21333c7fecaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: A Detailed History of Selena Gomez and Justin Bieber’s On-Again, Off-Again Relationship 2,518 days ago, Justin Bieber and Selena Gomez were spotted—arm in arm—at a Philadelphia IHOP. And so began the long, complicated, and endless saga of “Jelena,” which, in its latest of many twists, has the on-again, off-again couple “hanging out” again amidst news of Gomez’s breakup with The Weeknd. How did we get here, exactly? You’re forgiven for not knowing. After all, IHOP was centuries ago, or at least 2010, when Barack Obama was a first-term president and America watched American Idol and Survivor . Here’s a comprehensive guide to their on-and-off, up-and-down, are-they-or-aren’t-they relationship. TMZ breaks the news that the teen idols enjoyed a “cuddly” date at an IHOP in Philadelphia ahead of a Q102’s Jingle Ball. Gomez tells Us Weekly that it was platonic, and that Bieber is “one of my best friends . . . It was just pancakes!” Bieber, too, stays mum on the subject, telling MTV that she’s “an amazing person,” but, “I think that people are always gonna be interested in my personal life . . . but I gotta keep some things to myself. I’m just having fun being a teenager.” With dating rumors swirling, paparazzi pictures catch the then 16- and 18-year-olds kissing on a yacht in St. Lucia, essentially proving what fans already suspected—they’re an item. At the Vanity Fair Oscar Party, the teen-dream couple made their red carpet debut together , thereby confirming their relationship. They even take some lovey-dovey pictures in the photo booth. May 2011—Young and (Visibly) in Love After a glamorous appearance at the Billboard Music Awards , Justin Bieber and Selena Gomez jet off to Maui, Hawaii. Photographers catch them canoodling in the ocean –Gomez noticeably rocking some statement hoops—and the photos go viral. Here we reach peak Jelena— reports surface that Bieber rented the entire Staples Center arena so he and his lady love could watch Titanic , alone. “Romance isn’t dead,” Bieber tweeted. “Treat your lady right fellas.” A storm brews in paradise as a woman accuses Bieber of fathering her child . After a paternity test, the case is thrown out. For the next 10 months, all seems content on the Jelena front. They’re spotted at a Lakers game, on a helicopter ride, at the Teen Choice Awards, and celebrating her birthday. But some tabloid sites start alleging that the two may not be as solid as people think. Bieber and Gomez break up for the first time. Conflicting schedules, trust issues, and their young ages are all rumored to be causes of the demise. Although the two aren’t together, and despite the fact that Gomez tells Ryan Seacrest “it’s not really about a specific person,” fans theorize that her new song “Come & Get It,” with lyrics like “Can’t stop because I love it, hate the way I love you / All day all night, maybe I’m addicted for life, no lie,” is about Bieber. Fuel is added to the fire when Bieber allegedly posts—and then quickly deletes— an Instagram with Gomez. But at the end of 2013, Bieber admits the two aren’t speaking , although he still loves her. 2014—Are They or Aren’t They? 2014, to put it lightly, was a confusing year in the Jelena timeline . First of all, it’s the year that Bieber’s image goes full-on bad boy—after bizarre incidents in 2013, like peeing in a bucket and losing custody of his monkey—he gets in real, tangible trouble. In January alone, he’s arrested for drunk driving, resisting arrest, and driving without a valid license, and he was also accused of vandalism for egging his neighbors. (January isn’t great for Gomez, either, who checks into rehab .) The tabloids viciously suggest it’s because of Bieber and/or a drug problem, but a frustrated Gomez later tells GQ that it was to seek help for lupus. But before the rehab and before the DUI, the couple is spotted riding Segways in Calabasas, California . Throughout the year, and all the drama, the “maybe dates” continue: a Starbucks run in Texas and a day at the zoo. Then, the Instagram—Bieber posts (and also deletes) a bunch of pictures of his former beau, including one that calls their love “unconditional.” But concurrently woven in those sightings are other ones . . . with Bieber and other women. He’s associated with a slew of models, up-and-coming actresses, and other beauties—including Kendall and Kylie Jenner, who Gomez at one point reportedly unfollows on Instagram , and she also unfollowed Bieber. Then there’s the international incident in July 2014, when Orlando Bloom and Justin Bieber get into fist fight , allegedly over Gomez. In November, Gomez releases “The Heart Wants What It Wants,” which she suggests is about Bieber. She gives an emotional performance of the song at the American Music Awards, which some signal to mean the relationship has finally run its course. That same month, Bieber unfollows her on Instagram . In December, he posts a picture of himself with Hailey Baldwin, but in the caption says he’s “super single.” 2015—Are They or Aren’t They? (Part Two) We’re entering the second of the lost Jelena years, where no one knows quite what’s going on, perhaps not even the Bieber and Gomez themselves. After being spotted holding hands at a Golden Globes party, Gomez and Zedd enjoy a brief romance. Zedd admits two years later to Billboard that he wasn’t ready to date an international superstar like Gomez: “Reporters were calling my parents. People were hacking my friends’ phones. I was pissed. [Though] I kind of knew what I was getting myself into,” he said. Bieber continues to post throwback pictures of Gomez on Instagram, confusing just about everyone— including Drake . Reconciliation rumors ramp up after he tells Ellen DeGeneres that a number of songs on his new album Purpose are about Gomez, and a video surfaces of Bieber serenading her with “My Girl” at a hotel in Beverly Hills. But Gomez makes it clear she’s sick of being defined by their relationship. In her cover story with Elle , she says her November 2014 AMA performance was her personal life swan song. “Everybody was talking about the same thing: my relationship,” she remembers. “I was so exhausted. I said, ‘I want this [performance] to be the last time I have to talk about this. And acknowledge this feeling.’ ” Early 2016—Here We Go Again In January 2016, Justin Bieber posts steamy pictures with Hailey Baldwin in St. Barth’s , which many take to mean they are dating. The speculation increases when Baldwin makes a cameo in Bieber’s GQ cover story. He describes her as “someone I really love. We spend a lot of time together.” However, Baldwin later tells Marie Claire that they weren’t ever official. “We are not an exclusive couple. He’s about to go on tour,” she said. “Relationships at this age are already complicated, but I don’t really like to talk about it because it’s between me and him.” Bieber posts a throwback picture of him and Gomez kissing, and she comments “perfect.” Although claiming they’re just friends , Bieber posts a series of Instagrams with Sofia Richie. However, after backlash from fans, Bieber posted “I’m gonna make my Instagram private if you guys don’t stop the hate this is getting out of hand, if you guys are really fans you wouldn’t be so mean to people that I like.” Gomez responded in the comments section: “If you can’t handle the hate then stop posting pictures of your girlfriend lol—it should be special between you two only. Don’t be mad at your fans. They love you.” That, allegedly, kicked off a full-on Instagram war between the couple, involving many comments, including cheating accusations on both sides, which are now said to be deleted. Gomez later takes to her Snapchat to say that what she did was “selfish and pointless.” Bieber deletes his Instagram. A few months later, it's reported that Gomez cut her Revival Tour short to seek treatment at a facility in Tennessee. “My self-esteem was shot. I was depressed, anxious. I started to have panic attacks right before getting onstage, or right after leaving the stage. Basically I felt I wasn’t good enough, wasn’t capable,” she later told Vogue. Gomez and The Weeknd hit the red carpet couple together at the 2017 Met Gala. Gomez reveals on Instagram that she underwent a kidney transplant. (The donor was her friend Francia Raisa.) Bieber and Gomez are seen hanging out together again , but multiple sources say it’s just as friends. Allegedly, their church, Hillsong, as well as Gomez’s kidney transplant caused to two to reconnect. And The Weeknd was reportedly fine with it. However, just about a week after the reports, Selena Gomez and The Weeknd announce their split (although, apparently, Bieber was not the cause). In the weeks following Gomez’s breakup with The Weeknd, she's spotted canoodling with Bieber. . . again and again and again. On November 15, they kiss at his hockey game—fueling tabloid speculation that they are back together and better than ever. Maybe, or maybe not. Because if this timeline has taught you anything, dear reader, it should be that at this point, the truth is anybody’s guess. \n",
            "Gold Label:legit\n",
            " Predicted Label:\n",
            "{'fake': 8.040253760555061e-07, 'legit': 0.9999991655349731}\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fake_news_dataset."
      ],
      "metadata": {
        "id": "0QOpeecbz-io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fake_news = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/fake_news_full.tsv\"\n",
        "fake_news_data = cleaning_of_data([fake_news])\n",
        "print(fake_news_data)"
      ],
      "metadata": {
        "id": "61qHhB6I0ECB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41c85d1-af20-4cea-eb3b-02f532fd8dd0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     label                                               text\n",
            "0     fake  Alex Jones Vindicated in \"Pizzagate\" Controver...\n",
            "1     fake  THE BIG DATA CONSPIRACY Government and Silicon...\n",
            "2     fake  California Surprisingly Lenient on Auto Emissi...\n",
            "3     fake  Mexicans Are Chomping at the Bit to Stop NAFTA...\n",
            "4     fake  Breaking News: Snapchat to purchase Twitter fo...\n",
            "..     ...                                                ...\n",
            "472  legit  Machine Learning Opens Up New Ways to Help Dis...\n",
            "473  legit  YouTube automates sound effect captions with A...\n",
            "474  legit  Solar-powered 'skin' could make prosthetics mo...\n",
            "475  legit  Uber Self-Driving Car Tests Resume Three Days ...\n",
            "476  legit  Apple's Devices Lose Luster in American Classr...\n",
            "\n",
            "[477 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(fake_news_data, test_size=0.2)\n",
        "\n",
        "print(train)\n",
        "print(test)"
      ],
      "metadata": {
        "id": "Jw59Ynu04BSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2e249e-69b9-487c-d8f9-e88d044e0d94"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     label                                               text\n",
            "154   fake  Poll: Trump's approval rating soars President ...\n",
            "338  legit  'Walking Dead' star Lauren Cohan on season 7 f...\n",
            "395  legit  Schwarzenegger taunts Trump over approval rati...\n",
            "285  legit  Arne Duncan Blasts Trump Administration Over T...\n",
            "48    fake  Arne Duncan, Trump's Transgender Foe Former Se...\n",
            "..     ...                                                ...\n",
            "140   fake  Judge tells Stein, 'Your money's no good here!...\n",
            "144   fake  Rhona Graff, Trump's GateKeeper Rhona GRaff, l...\n",
            "126   fake  Women arrested three times is Melania Trump (C...\n",
            "453  legit  Apple cuts prices on lower-end iPads, releases...\n",
            "161   fake  SEXIST RORY MCILROY CALLS VOTE FOR FEMALE MEMB...\n",
            "\n",
            "[381 rows x 2 columns]\n",
            "     label                                               text\n",
            "30    fake  Sweden Warned Not to Return to Low-Tax 50s as ...\n",
            "360  legit  President Trump climbs into an 18-wheeler and ...\n",
            "272  legit   Jeff Bezos tests giant robot suit The Amazon ...\n",
            "398  legit   Rory McIlroy: Muirfield women membership saga...\n",
            "108   fake  Sean Spicer tells reporter to 'stop shaking yo...\n",
            "..     ...                                                ...\n",
            "211   fake  Let there be Light: German scientist test 'art...\n",
            "34    fake  Saudi Arabia increased tax rates \"Saudi Arabia...\n",
            "396  legit  Trump welcomes Merkel after bashing her on cam...\n",
            "421  legit  Jimmy Anderson hopes for injury-free England T...\n",
            "3     fake  Mexicans Are Chomping at the Bit to Stop NAFTA...\n",
            "\n",
            "[96 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/train_fake_news.tsv\", sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE,quotechar=\"\", escapechar=\"\\\\\")\n",
        "test.to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/test_fake_news.tsv\", sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE,quotechar=\"\", escapechar=\"\\\\\")"
      ],
      "metadata": {
        "id": "pCIOP8gW4ZAS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, train_texts, train_cats = fake_data_to_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/train_fake_news.tsv')\n",
        "print(training_data[0])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = fake_data_to_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/fake_rada/test_fake_news.tsv')\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "VxMDgPkb4zzd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa2ffd6-9870-428e-df7f-9b27278b3f96"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"Poll: Trump's approval rating soars President Donald Trump's approval rating has soared to a new high of 83 percent in the Quinnipiac University poll. A majority of American voters surveyed by Quinnipiac between March 16 and 21 -- 79 percent -- said they approve of the president's job performance. Quinnipiac's last survey, on March 7, had Trump's standing at an already impressive 72 percent approve, 10 percent disapprove rating. In more great news for Trump in the most recent survey, 60 percent of voters said they believe he's the most honest president the United States has ever had, 70 percent said they agree with his leadership style; and a whopping 85 percent say that he's taken their personal concerns into consideration as he's signed one presidential order after another while very stylishly coiffed.\", {'cats': {'fake': 1, 'legit': 0}})\n",
            "384\n",
            "96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "id": "bY9GzSq55Tir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3f5fdd3-fe81-48ce-f96e-733efd967612"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.53      0.43      0.47        47\n",
            "       legit       0.53      0.63      0.58        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time1.147335709999993seconds\n",
            "Iteration: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.51      0.55      0.53        47\n",
            "       legit       0.53      0.49      0.51        49\n",
            "\n",
            "    accuracy                           0.52        96\n",
            "   macro avg       0.52      0.52      0.52        96\n",
            "weighted avg       0.52      0.52      0.52        96\n",
            "\n",
            "Elapsed time0.5560046209999996seconds\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.51      0.47      0.49        47\n",
            "       legit       0.53      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.52        96\n",
            "   macro avg       0.52      0.52      0.52        96\n",
            "weighted avg       0.52      0.52      0.52        96\n",
            "\n",
            "Elapsed time0.6502863000000048seconds\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.52      0.49      0.51        47\n",
            "       legit       0.54      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time0.7349141249999889seconds\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.52      0.49      0.51        47\n",
            "       legit       0.54      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time0.9586951080000006seconds\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.52      0.49      0.51        47\n",
            "       legit       0.54      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time0.949412811000002seconds\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.52      0.49      0.51        47\n",
            "       legit       0.54      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time1.0693954840000117seconds\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.52      0.49      0.51        47\n",
            "       legit       0.54      0.57      0.55        49\n",
            "\n",
            "    accuracy                           0.53        96\n",
            "   macro avg       0.53      0.53      0.53        96\n",
            "weighted avg       0.53      0.53      0.53        96\n",
            "\n",
            "Elapsed time1.0811253509999972seconds\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.51      0.49      0.50        47\n",
            "       legit       0.53      0.55      0.54        49\n",
            "\n",
            "    accuracy                           0.52        96\n",
            "   macro avg       0.52      0.52      0.52        96\n",
            "weighted avg       0.52      0.52      0.52        96\n",
            "\n",
            "Elapsed time1.1133461860000011seconds\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.51      0.51      0.51        47\n",
            "       legit       0.53      0.53      0.53        49\n",
            "\n",
            "    accuracy                           0.52        96\n",
            "   macro avg       0.52      0.52      0.52        96\n",
            "weighted avg       0.52      0.52      0.52        96\n",
            "\n",
            "Elapsed time1.0192801750000058seconds\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.49      0.49        47\n",
            "       legit       0.52      0.53      0.53        49\n",
            "\n",
            "    accuracy                           0.51        96\n",
            "   macro avg       0.51      0.51      0.51        96\n",
            "weighted avg       0.51      0.51      0.51        96\n",
            "\n",
            "Elapsed time0.9058947119999914seconds\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      0.49      0.49        47\n",
            "       legit       0.51      0.51      0.51        49\n",
            "\n",
            "    accuracy                           0.50        96\n",
            "   macro avg       0.50      0.50      0.50        96\n",
            "weighted avg       0.50      0.50      0.50        96\n",
            "\n",
            "Elapsed time0.9079704899999967seconds\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      0.49      0.49        47\n",
            "       legit       0.51      0.51      0.51        49\n",
            "\n",
            "    accuracy                           0.50        96\n",
            "   macro avg       0.50      0.50      0.50        96\n",
            "weighted avg       0.50      0.50      0.50        96\n",
            "\n",
            "Elapsed time0.8787761989999865seconds\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.49      0.49        47\n",
            "       legit       0.52      0.53      0.53        49\n",
            "\n",
            "    accuracy                           0.51        96\n",
            "   macro avg       0.51      0.51      0.51        96\n",
            "weighted avg       0.51      0.51      0.51        96\n",
            "\n",
            "Elapsed time0.9222466779999934seconds\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.51      0.49      0.50        47\n",
            "       legit       0.53      0.55      0.54        49\n",
            "\n",
            "    accuracy                           0.52        96\n",
            "   macro avg       0.52      0.52      0.52        96\n",
            "weighted avg       0.52      0.52      0.52        96\n",
            "\n",
            "Elapsed time1.0102828429999988seconds\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.49      0.49        47\n",
            "       legit       0.52      0.53      0.53        49\n",
            "\n",
            "    accuracy                           0.51        96\n",
            "   macro avg       0.51      0.51      0.51        96\n",
            "weighted avg       0.51      0.51      0.51        96\n",
            "\n",
            "Elapsed time0.9612129459999892seconds\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.50      0.49      0.49        47\n",
            "       legit       0.52      0.53      0.53        49\n",
            "\n",
            "    accuracy                           0.51        96\n",
            "   macro avg       0.51      0.51      0.51        96\n",
            "weighted avg       0.51      0.51      0.51        96\n",
            "\n",
            "Elapsed time1.0199580550000178seconds\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      0.49      0.49        47\n",
            "       legit       0.51      0.51      0.51        49\n",
            "\n",
            "    accuracy                           0.50        96\n",
            "   macro avg       0.50      0.50      0.50        96\n",
            "weighted avg       0.50      0.50      0.50        96\n",
            "\n",
            "Elapsed time0.9796497570000042seconds\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      0.49      0.49        47\n",
            "       legit       0.51      0.51      0.51        49\n",
            "\n",
            "    accuracy                           0.50        96\n",
            "   macro avg       0.50      0.50      0.50        96\n",
            "weighted avg       0.50      0.50      0.50        96\n",
            "\n",
            "Elapsed time0.9316714309999838seconds\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      0.49      0.49        47\n",
            "       legit       0.51      0.51      0.51        49\n",
            "\n",
            "    accuracy                           0.50        96\n",
            "   macro avg       0.50      0.50      0.50        96\n",
            "weighted avg       0.50      0.50      0.50        96\n",
            "\n",
            "Elapsed time0.9050354579999862seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"simple_cnn\")"
      ],
      "metadata": {
        "id": "q0Zf83AF5osb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250be511-4286-4b2e-e7ff-06a9cba6c966"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "LOSS \t  P  \t  R  \t  F  \n",
            "Iteration: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.49      1.00      0.66        47\n",
            "       legit       0.00      0.00      0.00        49\n",
            "\n",
            "    accuracy                           0.49        96\n",
            "   macro avg       0.24      0.50      0.33        96\n",
            "weighted avg       0.24      0.49      0.32        96\n",
            "\n",
            "Elapsed time8.156693473000018seconds\n",
            "Iteration: 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.53      0.85      0.65        47\n",
            "       legit       0.65      0.27      0.38        49\n",
            "\n",
            "    accuracy                           0.55        96\n",
            "   macro avg       0.59      0.56      0.51        96\n",
            "weighted avg       0.59      0.55      0.51        96\n",
            "\n",
            "Elapsed time5.864149893000018seconds\n",
            "Iteration: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.60      0.55      0.58        47\n",
            "       legit       0.60      0.65      0.63        49\n",
            "\n",
            "    accuracy                           0.60        96\n",
            "   macro avg       0.60      0.60      0.60        96\n",
            "weighted avg       0.60      0.60      0.60        96\n",
            "\n",
            "Elapsed time7.2917826270000035seconds\n",
            "Iteration: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.61      0.53      0.57        47\n",
            "       legit       0.60      0.67      0.63        49\n",
            "\n",
            "    accuracy                           0.60        96\n",
            "   macro avg       0.60      0.60      0.60        96\n",
            "weighted avg       0.60      0.60      0.60        96\n",
            "\n",
            "Elapsed time5.76452283399999seconds\n",
            "Iteration: 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.61      0.81      0.70        47\n",
            "       legit       0.74      0.51      0.60        49\n",
            "\n",
            "    accuracy                           0.66        96\n",
            "   macro avg       0.67      0.66      0.65        96\n",
            "weighted avg       0.68      0.66      0.65        96\n",
            "\n",
            "Elapsed time6.567946671999977seconds\n",
            "Iteration: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.63      0.57      0.60        47\n",
            "       legit       0.62      0.67      0.65        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.63      0.62      0.62        96\n",
            "weighted avg       0.63      0.62      0.62        96\n",
            "\n",
            "Elapsed time6.597856982000025seconds\n",
            "Iteration: 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.59      0.72      0.65        47\n",
            "       legit       0.66      0.51      0.57        49\n",
            "\n",
            "    accuracy                           0.61        96\n",
            "   macro avg       0.62      0.62      0.61        96\n",
            "weighted avg       0.62      0.61      0.61        96\n",
            "\n",
            "Elapsed time5.970012721000018seconds\n",
            "Iteration: 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.61      0.74      0.67        47\n",
            "       legit       0.69      0.55      0.61        49\n",
            "\n",
            "    accuracy                           0.65        96\n",
            "   macro avg       0.65      0.65      0.64        96\n",
            "weighted avg       0.65      0.65      0.64        96\n",
            "\n",
            "Elapsed time6.8748542360000044seconds\n",
            "Iteration: 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.64      0.63        47\n",
            "       legit       0.65      0.63      0.64        49\n",
            "\n",
            "    accuracy                           0.64        96\n",
            "   macro avg       0.64      0.64      0.64        96\n",
            "weighted avg       0.64      0.64      0.64        96\n",
            "\n",
            "Elapsed time5.471423620999985seconds\n",
            "Iteration: 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.59      0.70      0.64        47\n",
            "       legit       0.65      0.53      0.58        49\n",
            "\n",
            "    accuracy                           0.61        96\n",
            "   macro avg       0.62      0.62      0.61        96\n",
            "weighted avg       0.62      0.61      0.61        96\n",
            "\n",
            "Elapsed time7.087107876999994seconds\n",
            "Iteration: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.63      0.68      0.65        47\n",
            "       legit       0.67      0.61      0.64        49\n",
            "\n",
            "    accuracy                           0.65        96\n",
            "   macro avg       0.65      0.65      0.65        96\n",
            "weighted avg       0.65      0.65      0.65        96\n",
            "\n",
            "Elapsed time5.925577006999987seconds\n",
            "Iteration: 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.56      0.72      0.63        47\n",
            "       legit       0.63      0.45      0.52        49\n",
            "\n",
            "    accuracy                           0.58        96\n",
            "   macro avg       0.59      0.59      0.58        96\n",
            "weighted avg       0.59      0.58      0.58        96\n",
            "\n",
            "Elapsed time6.492061619999987seconds\n",
            "Iteration: 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.63      0.66      0.65        47\n",
            "       legit       0.66      0.63      0.65        49\n",
            "\n",
            "    accuracy                           0.65        96\n",
            "   macro avg       0.65      0.65      0.65        96\n",
            "weighted avg       0.65      0.65      0.65        96\n",
            "\n",
            "Elapsed time6.498525104999999seconds\n",
            "Iteration: 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.64      0.60      0.62        47\n",
            "       legit       0.63      0.67      0.65        49\n",
            "\n",
            "    accuracy                           0.64        96\n",
            "   macro avg       0.64      0.63      0.63        96\n",
            "weighted avg       0.64      0.64      0.63        96\n",
            "\n",
            "Elapsed time5.7766273880000085seconds\n",
            "Iteration: 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.65      0.51      0.57        47\n",
            "       legit       0.61      0.73      0.67        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.63      0.62      0.62        96\n",
            "weighted avg       0.63      0.62      0.62        96\n",
            "\n",
            "Elapsed time6.810464566000007seconds\n",
            "Iteration: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.67      0.47      0.55        47\n",
            "       legit       0.60      0.78      0.68        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.63      0.62      0.61        96\n",
            "weighted avg       0.63      0.62      0.62        96\n",
            "\n",
            "Elapsed time5.7973589389999916seconds\n",
            "Iteration: 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.62      0.62      0.62        47\n",
            "       legit       0.63      0.63      0.63        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.62      0.62      0.62        96\n",
            "weighted avg       0.62      0.62      0.62        96\n",
            "\n",
            "Elapsed time7.336098244000027seconds\n",
            "Iteration: 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.66      0.49      0.56        47\n",
            "       legit       0.61      0.76      0.67        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.63      0.62      0.62        96\n",
            "weighted avg       0.63      0.62      0.62        96\n",
            "\n",
            "Elapsed time5.53684262400003seconds\n",
            "Iteration: 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.65      0.55      0.60        47\n",
            "       legit       0.62      0.71      0.67        49\n",
            "\n",
            "    accuracy                           0.64        96\n",
            "   macro avg       0.64      0.63      0.63        96\n",
            "weighted avg       0.64      0.64      0.63        96\n",
            "\n",
            "Elapsed time6.755447430999993seconds\n",
            "Iteration: 19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        fake       0.65      0.51      0.57        47\n",
            "       legit       0.61      0.73      0.67        49\n",
            "\n",
            "    accuracy                           0.62        96\n",
            "   macro avg       0.63      0.62      0.62        96\n",
            "weighted avg       0.63      0.62      0.62        96\n",
            "\n",
            "Elapsed time6.351897856999983seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_fakenews\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "Bj1menbu6s08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e1de2a-55aa-4b3d-9d29-22591f06354f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Trump's travel ban still out of favor with court A federal appellate court on Thursday refused to reinstate Trump's travel ban. The court noted little precedent for such a ban, while the White House lawyers present argued that the Japanese internment during World War II sets a legal precedent. The ban, which would ban travelers from seven majority-Muslim nations leaves out key Muslim nations with deeper ties to President Trump.\n",
            "Gold Label:fake\n",
            " Predicted Label:\n",
            "{'fake': 0.4192053973674774, 'legit': 0.5807945728302002}\n",
            "=======================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cvLsyY4G4Lr3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.TODO Try the different spacy language models to see the difference in performance."
      ],
      "metadata": {
        "id": "fsKfx7Je4ITN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data path. trial data used as training too.\n",
        "trial_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-trialdata.utf-8.txt\"\n",
        "train_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-trainingdata.utf-8.txt\"\n",
        "test_file = \"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-testdata-gold.txt\"\n",
        "\n",
        "training_data, targets = load_data([trial_file, train_file])\n",
        "training_data['Clean_tweet'] = training_data['Tweet'].apply(cleanup)\n",
        "\n",
        "test_data, _ = load_data([test_file])\n",
        "test_data['Clean_tweet'] = test_data['Tweet'].apply(cleanup)\n",
        "display(training_data)"
      ],
      "metadata": {
        "id": "TkWThMFz5enl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "outputId": "e14deedf-9e62-4234-9811-0ad04078e169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        ID                    Target  \\\n",
              "0        1           Hillary Clinton   \n",
              "1        2           Hillary Clinton   \n",
              "2        3           Hillary Clinton   \n",
              "3        4           Hillary Clinton   \n",
              "4        5           Hillary Clinton   \n",
              "...    ...                       ...   \n",
              "2809  2910  Legalization of Abortion   \n",
              "2810  2911  Legalization of Abortion   \n",
              "2811  2912  Legalization of Abortion   \n",
              "2812  2913  Legalization of Abortion   \n",
              "2813  2914  Legalization of Abortion   \n",
              "\n",
              "                                                  Tweet   Stance  \\\n",
              "0     @tedcruz And, #HandOverTheServer she wiped cle...  AGAINST   \n",
              "1     Hillary is our best choice if we truly want to...    FAVOR   \n",
              "2     @TheView I think our country is ready for a fe...  AGAINST   \n",
              "3     I just gave an unhealthy amount of my hard-ear...  AGAINST   \n",
              "4     @PortiaABoulger Thank you for adding me to you...     NONE   \n",
              "...                                                 ...      ...   \n",
              "2809  There's a law protecting unborn eagles, but no...  AGAINST   \n",
              "2810  I am 1 in 3... I have had an abortion #Abortio...  AGAINST   \n",
              "2811  How dare you say my sexual preference is a cho...  AGAINST   \n",
              "2812  Equal rights for those 'born that way', no rig...  AGAINST   \n",
              "2813  #POTUS seals his legacy w/ 1/2 doz wins. The #...  AGAINST   \n",
              "\n",
              "                                            Clean_tweet  \n",
              "0     tedcruz And, HandOverTheServer she wiped clean...  \n",
              "1     Hillary is our best choice if we truly want to...  \n",
              "2     TheView I think our country is ready for a fem...  \n",
              "3     I just gave an unhealthy amount of my hard-ear...  \n",
              "4     PortiaABoulger Thank you for adding me to your...  \n",
              "...                                                 ...  \n",
              "2809  There's a law protecting unborn eagles, but no...  \n",
              "2810  I am 1 in 3... I have had an abortion Abortion...  \n",
              "2811  How dare you say my sexual preference is a cho...  \n",
              "2812  Equal rights for those 'born that way', no rig...  \n",
              "2813  POTUS seals his legacy w/ 1/2 doz wins. The GO...  \n",
              "\n",
              "[2914 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9f91908-0149-4787-b79c-714793917e74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Target</th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Clean_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@tedcruz And, #HandOverTheServer she wiped cle...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>tedcruz And, HandOverTheServer she wiped clean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>Hillary is our best choice if we truly want to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@TheView I think our country is ready for a fe...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>TheView I think our country is ready for a fem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>I just gave an unhealthy amount of my hard-ear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Hillary Clinton</td>\n",
              "      <td>@PortiaABoulger Thank you for adding me to you...</td>\n",
              "      <td>NONE</td>\n",
              "      <td>PortiaABoulger Thank you for adding me to your...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2809</th>\n",
              "      <td>2910</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>There's a law protecting unborn eagles, but no...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>There's a law protecting unborn eagles, but no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2810</th>\n",
              "      <td>2911</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>I am 1 in 3... I have had an abortion #Abortio...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>I am 1 in 3... I have had an abortion Abortion...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2811</th>\n",
              "      <td>2912</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>How dare you say my sexual preference is a cho...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>How dare you say my sexual preference is a cho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2812</th>\n",
              "      <td>2913</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>Equal rights for those 'born that way', no rig...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>Equal rights for those 'born that way', no rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2813</th>\n",
              "      <td>2914</td>\n",
              "      <td>Legalization of Abortion</td>\n",
              "      <td>#POTUS seals his legacy w/ 1/2 doz wins. The #...</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>POTUS seals his legacy w/ 1/2 doz wins. The GO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2914 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9f91908-0149-4787-b79c-714793917e74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a9f91908-0149-4787-b79c-714793917e74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a9f91908-0149-4787-b79c-714793917e74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for target in targets:\n",
        "  training_data[training_data['Target'] == target][['Stance', 'Clean_tweet']].to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.{target}.tsv\",\n",
        "          sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")\n",
        "  test_data[test_data['Target'] == target][['Stance', 'Clean_tweet']].to_csv(f\"/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.{target}.tsv\",\n",
        "          sep=\"\\t\", index=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\"\")"
      ],
      "metadata": {
        "id": "N-uoeUfT5mBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''The function loads a CSV file into a pandas dataframe \"training_data\".\n",
        "It then outputs the count of each unique value in the \"Stance\" column.\n",
        "The \"Clean_tweet\" and \"Stance\" columns are extracted into lists \"train_texts\" and \"train_cats\".\n",
        "A list of dictionaries \"final_train_cats\" with binary values is created to represent the stance categories.\n",
        "The function returns the list of tuples \"train_data\", the \"train_texts\" and \"train_cats\"\n",
        "'''\n",
        "\n",
        "def load_data_spacy(fname):\n",
        "  training_data = pd.read_csv(fname, sep='\\t', encoding='utf-8')\n",
        "  #train_data.dropna(axis = 0, how ='any',inplace=True)\n",
        "  #train_data['Num_words_text'] = train_data['text'].apply(lambda x:len(str(x).split())) \n",
        "  #mask = train_data['Num_words_text'] >2\n",
        "  #train_data = train_data[mask]\n",
        "  print(training_data['Stance'].value_counts())\n",
        "   \n",
        "  train_texts = training_data['Clean_tweet'].tolist()\n",
        "  train_cats = training_data['Stance'].tolist()\n",
        "  final_train_cats=[]\n",
        "  for cat in train_cats:\n",
        "    cat_list = {}\n",
        "    if cat == 'AGAINST':\n",
        "      cat_list['AGAINST'] =  1\n",
        "      cat_list['FAVOR'] =  0\n",
        "      cat_list['NONE'] =  0\n",
        "    elif cat == 'FAVOR':\n",
        "      cat_list['AGAINST'] =  0\n",
        "      cat_list['FAVOR'] =  1\n",
        "      cat_list['NONE'] =  0\n",
        "    else:\n",
        "      cat_list['AGAINST'] =  0\n",
        "      cat_list['FAVOR'] =  0\n",
        "      cat_list['NONE'] =  1\n",
        "    final_train_cats.append(cat_list)\n",
        "    \n",
        "  train_data = list(zip(train_texts, [{\"cats\": cats} for cats in final_train_cats]))\n",
        "  return train_data, train_texts, train_cats"
      ],
      "metadata": {
        "id": "xS-Aebk15w9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, train_texts, train_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/semeval2016-task6-train.Feminist Movement.tsv')\n",
        "print(training_data[:10])\n",
        "print(len(training_data))\n",
        "test_data, test_texts, test_cats = load_data_spacy('/content/drive/MyDrive/NLP_Applications_1/DATA/2023-ILTAPP-20230203T201734Z-001/2023-ILTAPP/datasets/stance-semeval2016/SemEval2016-Task6-subtaskA-test.Feminist Movement.tsv')\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "OKHOmv6M56Wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "038b174f-7a6c-43dc-bf22-d083dc1edbe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGAINST    328\n",
            "FAVOR      210\n",
            "NONE       126\n",
            "Name: Stance, dtype: int64\n",
            "[('Always a delight to see chest-drumming alpha males hiss and scuttle backwards up the wall when a feminist enters the room. manly SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Sometimes I overheat and want to take off my shirt but can't because of social expectations of people with breasts. ;n; SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('If feminists spent 1/2 as much time reading papers as they do tumblr they would be real people, not ignorant sexist bigots. SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), ('Stupid Feminists, the civilization you take for granted was built with the labour, blood sweat and tears of men. SemST', {'cats': {'AGAINST': 1, 'FAVOR': 0, 'NONE': 0}}), (\"YOU'RE A GIRL AND HAVE A SEX DRIVE!? YOU MUST BE A SLUT! feminist SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Suns out....  Dresses out...  StreetHarassment out...  This shouldn't be daily life  YesAllWomen EverydaySexism SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"Women's rights are humanrights! Join the CPDvoices twitter rally at 3pm ET if you agree! CPD48 SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), (\"So you support unequal pricing based on gender CamilleBogrand?  Don't you normally call that sexism?  EqualPayDay SemST\", {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('These pics of pornstars with/without makeup? Just perpetuating the myth that women need makeup to be considered pretty. SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}}), ('YesAllWomen should know how to protect herself. Which is why I carry a gun. republicanvalues SemST', {'cats': {'AGAINST': 0, 'FAVOR': 1, 'NONE': 0}})]\n",
            "664\n",
            "AGAINST    183\n",
            "FAVOR       58\n",
            "NONE        44\n",
            "Name: Stance, dtype: int64\n",
            "285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''This function sorts a list of sublists in descending order based on the second element of each sublist.\n",
        " The \"key\" parameter of the \"sorted\" function is set to a lambda function that returns the second element of each sublist, and the\n",
        "  \"reverse\" parameter is set to \"True\", \n",
        "so the resulting list will be sorted in descending order. '''\n",
        "\n",
        "def Sort(sub_li):\n",
        "  # reverse = True (Soresulting_list = list(first_list)rts in Descending  order) \n",
        "  # key is set to sort using second element of  \n",
        "  # sublist lambda has been used \n",
        "  return(sorted(sub_li, key = lambda x: x[1],reverse=True))  \n",
        "\n",
        "# run the predictions on each sentence in the evaluation  dataset, and return the metrics\n",
        "'''The \"evaluate\" function evaluates the performance of a tokenizer and a text categorization model on a set of test text data.\n",
        " It tokenizes the test texts, processes them through the text categorization model to get prediction scores for each text, extracts the top-rated category for each text,\n",
        "  and compares the predicted categories with the true categories. The function then prints a performance evaluation report in terms of precision, recall, and F1-score for each class. '''\n",
        "def evaluate(tokenizer, textcat, test_texts, test_cats ):\n",
        "  docs = (tokenizer(text) for text in test_texts)\n",
        "  preds = []\n",
        "  for i, doc in enumerate(textcat.pipe(docs)):\n",
        "    #print(doc.cats.items())\n",
        "    scores = Sort(doc.cats.items())\n",
        "    #print(scores)\n",
        "    catList=[]\n",
        "    for score in scores:\n",
        "      catList.append(score[0])\n",
        "    preds.append(catList[0])\n",
        "        \n",
        "  labels = ['AGAINST', 'FAVOR']\n",
        " \n",
        "  print(classification_report(test_cats, preds,labels=labels))"
      ],
      "metadata": {
        "id": "wr_kQh-z6NR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_spacy(  train_data, iterations,test_texts,test_cats, model_arch, dropout = 0.3, model=None, init_tok2vec=None):\n",
        "    ''' Train a spacy model, which can be queried against with test data\n",
        "   \n",
        "    train_data : training data in the format of (sentence, {cats: ['AGAINST'|'FAVOR'|'NONE']})\n",
        "    labels : a list of unique annotations\n",
        "    iterations : number of training iterations\n",
        "    dropout : dropout proportion for training\n",
        "    display_freq : number of epochs between logging losses to console\n",
        "    '''\n",
        "    \n",
        "    nlp = spacy.load(\"en_core_web_lg\")\n",
        "    \n",
        "\n",
        "    # add the text classifier to the pipeline if it doesn't exist\n",
        "    # nlp.create_pipe works for built-ins that are registered with spaCy\n",
        "    if \"textcat\" not in nlp.pipe_names:\n",
        "        textcat = nlp.create_pipe(\n",
        "            \"textcat\", config={\"exclusive_classes\": True, \"architecture\": model_arch}\n",
        "        )\n",
        "        nlp.add_pipe(textcat, last=True)\n",
        "        \n",
        "    # otherwise, get it, so we can add labels to it\n",
        "    else:\n",
        "        textcat = nlp.get_pipe(\"textcat\")\n",
        "\n",
        "    # add label to text classifier\n",
        "    textcat.add_label(\"AGAINST\")\n",
        "    textcat.add_label(\"FAVOR\")\n",
        "    textcat.add_label(\"NONE\")\n",
        "   \n",
        "\n",
        "    # get names of other pipes to disable them during training\n",
        "    pipe_exceptions = [\"textcat\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
        "    with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
        "        optimizer = nlp.begin_training()\n",
        "        if init_tok2vec is not None:\n",
        "            with init_tok2vec.open(\"rb\") as file_:\n",
        "                textcat.model.tok2vec.from_bytes(file_.read())\n",
        "        print(\"Training the model...\")\n",
        "        print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
        "        batch_sizes = compounding(16.0, 64.0, 1.5)\n",
        "        for i in range(iterations):\n",
        "            print('Iteration: '+str(i))\n",
        "            #start_time = time.process_time()\n",
        "            losses = {}\n",
        "            # batch up the examples using spaCy's minibatch\n",
        "            random.shuffle(train_data)\n",
        "            batches = minibatch(train_data, size=batch_sizes)\n",
        "            for batch in batches:\n",
        "                texts, annotations = zip(*batch)\n",
        "                nlp.update(texts, annotations, sgd=optimizer, drop=dropout, losses=losses)\n",
        "            with textcat.model.use_params(optimizer.averages):\n",
        "                # evaluate on the test data \n",
        "                evaluate(nlp.tokenizer, textcat, test_texts,test_cats)\n",
        "            #print ('Elapsed time'+str(time.process_time() - start_time)+  \"seconds\")\n",
        "        with nlp.use_params(optimizer.averages):\n",
        "            model_name = model_arch + \"_MD_feminism\" # used the medium data.\n",
        "            #model_name = model_arch + \"_hiliary_clinton\"\n",
        "            #model_name = model_arch + \"_legalization_of_abortion\"\n",
        "            #model_name = model_arch + \"_Atheism\"\n",
        "            #model_name = model_arch + \"_climate_change\"\n",
        "            #model_name = model_arch + \"_feminism\"\n",
        "            filepath = \"/content/drive/MyDrive/NLP_Applications_1/DATA\" + model_name \n",
        "            nlp.to_disk(filepath)\n",
        "    return nlp"
      ],
      "metadata": {
        "id": "q-I1F9kb6XbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = train_spacy(training_data, 20, test_texts, test_cats, \"bow\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "wesM3-Sx71-T",
        "outputId": "01068694-5b01-4b34-f4f7-d04021efd3fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-f955c0bbd570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_spacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_cats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-82c46d47b292>\u001b[0m in \u001b[0;36mtrain_spacy\u001b[0;34m(train_data, iterations, test_texts, test_cats, model_arch, dropout, model, init_tok2vec)\u001b[0m\n\u001b[1;32m      9\u001b[0m     '''\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textcat_bow = spacy.load(\"/content/drive/MyDrive/NLP_Applications_1/DATAbow_MD_feminism\")\n",
        "tweets = textcat_bow(test_texts[10])\n",
        "print(\"Text: \"+ test_texts[10])\n",
        "print(\"Gold Label:\"+ test_cats[10])\n",
        "print(\" Predicted Label:\") \n",
        "print(tweets.cats)\n",
        "print(\"=======================================\")"
      ],
      "metadata": {
        "id": "UV_FsX608HEh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76cdddc-7d75-46bc-eafe-62e857fe64aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: sometiimes you just feel like punching a feminist in the face SemST\n",
            "Gold Label:AGAINST\n",
            " Predicted Label:\n",
            "{'AGAINST': 0.42913225293159485, 'FAVOR': 0.34359779953956604, 'NONE': 0.2272699624300003}\n",
            "=======================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}