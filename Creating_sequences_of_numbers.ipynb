{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_0yRkucjtrkK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I ate an apple','I love apples','apples taste good', 'I would like to eat an apple during summer']"
      ],
      "metadata": {
        "id": "Kf3PkelBuCT6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJA3FVvFuGN4",
        "outputId": "5f1d6c42-98b4-4a76-ab04-5fdeaa0b7bd3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'an': 2, 'apple': 3, 'apples': 4, 'ate': 5, 'love': 6, 'taste': 7, 'good': 8, 'would': 9, 'like': 10, 'to': 11, 'eat': 12, 'during': 13, 'summer': 14}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "GBO85fivuJQW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22a52yF0uVk_",
        "outputId": "4141c0e4-9ae9-440a-c4cd-7b1b0093447c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5, 2, 3], [1, 6, 4], [4, 7, 8], [1, 9, 10, 11, 12, 2, 3, 13, 14]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How does the tokenizer handle the data that is not present in training"
      ],
      "metadata": {
        "id": "O8WT_O7Zu21J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"I ate an orange\",\"I came from Hyderabad\"]"
      ],
      "metadata": {
        "id": "Z-DHQ-0iu1S2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq = tokenizer.texts_to_sequences(test)"
      ],
      "metadata": {
        "id": "nZWMDicsvJdD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Here we see that Tokenizer ignores the data that It has not seen."
      ],
      "metadata": {
        "id": "RigBfHD5vafm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAODn84nvVGm",
        "outputId": "2568af3c-ee0c-4280-92c8-345010e15ab6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 5, 2], [1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inorder to not to loose the length of the sequence of the word we can use <OOV> parameter."
      ],
      "metadata": {
        "id": "BXYutheUvyRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "vkff9XS_v8fc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I ate an apple','I love apples','apples taste good', 'I would like to eat an apple during summer']"
      ],
      "metadata": {
        "id": "Oag7fpudwMru"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token = \"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LknAvhE8wR0e",
        "outputId": "9bac7162-f0df-4476-a1bc-796a52414fa3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'i': 2, 'an': 3, 'apple': 4, 'apples': 5, 'ate': 6, 'love': 7, 'taste': 8, 'good': 9, 'would': 10, 'like': 11, 'to': 12, 'eat': 13, 'during': 14, 'summer': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "cWAzUzbqwkiZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boqZ2KJNwzUR",
        "outputId": "5d6b111e-99a8-488a-c448-8b34567b104d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 6, 3, 4], [2, 7, 5], [5, 8, 9], [2, 10, 11, 12, 13, 3, 4, 14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"I ate an orange\",\"I came from Hyderabad\"]"
      ],
      "metadata": {
        "id": "GAdtf7Kkwm-m"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq = tokenizer.texts_to_sequences(test)"
      ],
      "metadata": {
        "id": "_zrDSSh4wpF3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaIPNdirwuB7",
        "outputId": "a3cfccba-f7fb-4a2b-c0f7-93900bbc483a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 6, 3, 1], [2, 1, 1, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padding to capture the sizes of different sentences."
      ],
      "metadata": {
        "id": "E1A2sbZA1OLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "dxvS6pp51U4T"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I ate an apple','I love apples','apples taste good', 'I would like to eat an apple during summer']"
      ],
      "metadata": {
        "id": "dMy9eaV61gyt"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words = 100, oov_token = \"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KFPBeNx1jM0",
        "outputId": "20555a26-876c-402e-911c-96ba50913eee"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'i': 2, 'an': 3, 'apple': 4, 'apples': 5, 'ate': 6, 'love': 7, 'taste': 8, 'good': 9, 'would': 10, 'like': 11, 'to': 12, 'eat': 13, 'during': 14, 'summer': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(sentences)"
      ],
      "metadata": {
        "id": "FqTQhDSu1lLv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIll5cGL1mCO",
        "outputId": "23e1af3f-07e0-4faf-fb2d-919c2372e10e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 6, 3, 4], [2, 7, 5], [5, 8, 9], [2, 10, 11, 12, 13, 3, 4, 14, 15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded = pad_sequences(sequences)"
      ],
      "metadata": {
        "id": "6yljPDVX2JqJ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if we keep post it means zeros will appear after.\n",
        "padded = pad_sequences(sequences,padding = 'post')"
      ],
      "metadata": {
        "id": "m_Jbpt4t2wKB"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if you donot want the padding to the the maximum length of the sentence then what we can do is pu max lenth.\n",
        "padded = pad_sequences(sequences,padding= 'post', maxlen = 5)"
      ],
      "metadata": {
        "id": "GY8Ok6Of3PXy"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#truncation can be pre or post.\n",
        "padded = pad_sequences(sequences, padding= 'post', truncating = 'post', maxlen = 5)"
      ],
      "metadata": {
        "id": "DgBYb26Z31i2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_index)\n",
        "print(sequences)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8CStcAv2TQ2",
        "outputId": "16f8466a-77f0-461b-aefa-cacb01b1db65"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'i': 2, 'an': 3, 'apple': 4, 'apples': 5, 'ate': 6, 'love': 7, 'taste': 8, 'good': 9, 'would': 10, 'like': 11, 'to': 12, 'eat': 13, 'during': 14, 'summer': 15}\n",
            "[[2, 6, 3, 4], [2, 7, 5], [5, 8, 9], [2, 10, 11, 12, 13, 3, 4, 14, 15]]\n",
            "[[ 2  6  3  4  0]\n",
            " [ 2  7  5  0  0]\n",
            " [ 5  8  9  0  0]\n",
            " [ 2 10 11 12 13]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"I ate an orange\",\"I came from Hyderabad\"]"
      ],
      "metadata": {
        "id": "h49N9RMq1sFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq = tokenizer.texts_to_sequences(test)"
      ],
      "metadata": {
        "id": "6cQintfA1uE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_seq)"
      ],
      "metadata": {
        "id": "hkXTiAQP1uwM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}